"""
================================================================================
DEPRECATED - DO NOT EDIT THIS FILE
================================================================================

This file is DEPRECATED and kept only for reference/backup purposes.

The ACTIVE route implementations are now in the modular blueprint files:
    src/backend/app/routes/
        - auth.py              -> Authentication routes
        - organization.py      -> Organization management routes
        - phase1_maturity.py   -> Phase 1 maturity assessment routes
        - phase1_roles.py      -> Phase 1 role management routes
        - phase1_strategies.py -> Phase 1 strategy selection routes
        - phase2_assessment.py -> Phase 2 competency assessment routes [ACTIVE]
        - phase2_learning.py   -> Phase 2 learning objectives routes
        - main.py              -> Miscellaneous/utility routes

If you need to modify route behavior, edit the corresponding file in routes/

This file was deprecated on 2025-12-05 after discovering that edits here
were not taking effect because the blueprint files were being loaded instead.

================================================================================
OLD CONTENT BELOW - FOR REFERENCE ONLY
================================================================================
"""

from flask import Blueprint, request, jsonify, current_app
from flask_jwt_extended import jwt_required, get_jwt_identity, create_access_token, get_jwt
from datetime import datetime, timedelta
import json
import sys
import traceback
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError
from collections import defaultdict

from models import (
    db,
    User,
    SECompetency,
    SERole,
    Organization,
    CompetencyAssessment,
    RoleCluster,
    OrganizationRoles,
    OrganizationRoleMapping,
    IsoProcesses,
    Competency,
    CompetencyIndicator,
    RoleProcessMatrix,
    ProcessCompetencyMatrix,
    RoleCompetencyMatrix,
    UnknownRoleProcessMatrix,
    UnknownRoleCompetencyMatrix,
    UserCompetencySurveyResults,
    UserRoleCluster,
    UserCompetencySurveyFeedback,
    LearningStrategy,
    OrganizationPMTContext,
    calculate_maturity_score,
    select_archetype
)

# Import LLM feedback generation
from app.generate_survey_feedback import generate_feedback_with_llm

# Import AI Role Mapping Service
from app.services.role_cluster_mapping_service import RoleClusterMappingService

# Import AI Custom Role Matrix Generator
from app.services.custom_role_matrix_generator import CustomRoleMatrixGenerator

# Import Phase 2 Task 3 setup function
import os
import sys
# Add setup directory to path
setup_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'setup'))
if setup_path not in sys.path:
    sys.path.insert(0, setup_path)
from setup_phase2_task3_for_org import setup_phase2_task3_strategies

# =============================================================================
# BLUEPRINT 1: Main SE-QPT Platform Routes
# =============================================================================

main_bp = Blueprint('main', __name__)

# Initialize AI Role Mapping Service
role_mapping_service = RoleClusterMappingService()

# Initialize AI Custom Role Matrix Generator
custom_role_matrix_generator = CustomRoleMatrixGenerator()

@main_bp.route('/')
def index():
    """Platform welcome endpoint"""
    return {
        'message': 'SE-QPT Unified Platform API',
        'version': '1.0.0',
        'description': 'Systems Engineering Qualification Planning Tool with RAG-LLM Innovation',
        'components': {
            'marcel_methodology': 'SE-QPT 4-phase framework',
            'derik_assessor': 'Competency assessment system',
            'rag_innovation': 'AI-powered learning objective generation'
        },
        'endpoints': {
            'assessments': '/api/assessments',
            'competencies': '/api/competencies',
            'learning_objectives': '/api/learning-objectives',
            'qualification_plans': '/api/qualification-plans',
            'admin': '/admin',
            'auth': '/auth'
        }
    }

# Assessment Endpoints
@main_bp.route('/assessments', methods=['GET'])
@jwt_required()
def get_assessments():
    """Get user's assessments"""
    try:
        user_id = int(get_jwt_identity())
        assessments = Assessment.query.filter_by(user_id=user_id).all()

        return {
            'assessments': [
                {
                    'id': a.id,
                    'uuid': a.uuid,
                    'type': a.assessment_type,
                    'phase': a.phase,
                    'status': a.status,
                    'progress': a.progress_percentage,
                    'organization': a.organization_name,
                    'started_at': a.started_at.isoformat() if a.started_at else None,
                    'completed_at': a.completed_at.isoformat() if a.completed_at else None
                } for a in assessments
            ]
        }
    except Exception as e:
        return {'error': str(e)}, 500

@main_bp.route('/assessments', methods=['POST'])
@jwt_required()
def create_assessment():
    """Create new assessment"""
    try:
        user_id = int(get_jwt_identity())
        data = request.get_json()

        assessment = Assessment(
            user_id=user_id,
            assessment_type=data.get('type', 'comprehensive'),
            phase=data.get('phase', 1),
            organization_name=data.get('organization_name'),
            industry_domain=data.get('industry_domain'),
            organization_size=data.get('organization_size')
        )

        db.session.add(assessment)
        db.session.commit()

        return {
            'message': 'Assessment created successfully',
            'assessment': {
                'id': assessment.id,
                'uuid': assessment.uuid,
                'type': assessment.assessment_type,
                'phase': assessment.phase
            }
        }
    except Exception as e:
        db.session.rollback()
        return {'error': str(e)}, 500

@main_bp.route('/assessments/<assessment_uuid>', methods=['GET'])
@jwt_required()
def get_assessment(assessment_uuid):
    """Get specific assessment details"""
    try:
        user_id = int(get_jwt_identity())
        assessment = Assessment.query.filter_by(uuid=assessment_uuid, user_id=user_id).first()

        if not assessment:
            return {'error': 'Assessment not found'}, 404

        return {
            'assessment': {
                'id': assessment.id,
                'uuid': assessment.uuid,
                'type': assessment.assessment_type,
                'phase': assessment.phase,
                'status': assessment.status,
                'progress': assessment.progress_percentage,
                'organization_name': assessment.organization_name,
                'industry_domain': assessment.industry_domain,
                'se_maturity_level': assessment.se_maturity_level,
                'results': assessment.results,
                'competency_scores': assessment.competency_scores,
                'gap_analysis': assessment.gap_analysis,
                'recommendations': assessment.recommendations,
                'started_at': assessment.started_at.isoformat() if assessment.started_at else None,
                'completed_at': assessment.completed_at.isoformat() if assessment.completed_at else None
            }
        }
    except Exception as e:
        return {'error': str(e)}, 500

# Competency Endpoints
# NOTE: Duplicate /competencies endpoint removed - see line 2812 for the correct implementation using Competency model

# NOTE: Duplicate /roles endpoint - check if SERole model exists or use RoleCluster
@main_bp.route('/roles', methods=['GET'])
def get_roles():
    """Get all SE roles"""
    try:
        # Using RoleCluster instead of SERole which doesn't exist
        roles = RoleCluster.query.all()

        return {
            'roles': [
                {
                    'id': r.id,
                    'name': r.name,
                    'description': r.description,
                    'typical_responsibilities': r.typical_responsibilities,
                    'career_level': r.career_level,
                    'primary_focus': r.primary_focus
                } for r in roles
            ]
        }
    except Exception as e:
        return {'error': str(e)}, 500

# @main_bp.route('/role-competency-matrix', methods=['GET'])
# def get_role_competency_matrix():
#     """Get the 14x16 role-competency matrix"""
#     # This endpoint is temporarily disabled until RoleCompetencyMatrix model is implemented
#     return {'message': 'Role-competency matrix endpoint temporarily disabled'}, 501

# Qualification Archetype Endpoints
@main_bp.route('/archetypes', methods=['GET'])
def get_archetypes():
    """Get qualification archetypes"""
    try:
        archetypes = QualificationArchetype.query.filter_by(is_active=True).all()

        return {
            'archetypes': [
                {
                    'id': a.id,
                    'name': a.name,
                    'description': a.description,
                    'typical_duration': a.typical_duration,
                    'learning_format': a.learning_format,
                    'target_audience': a.target_audience,
                    'focus_area': a.focus_area,
                    'delivery_method': a.delivery_method
                } for a in archetypes
            ]
        }
    except Exception as e:
        return {'error': str(e)}, 500

# Qualification Plan Endpoints
@main_bp.route('/qualification-plans', methods=['GET'])
@jwt_required()
def get_qualification_plans():
    """Get user's qualification plans"""
    try:
        user_id = int(get_jwt_identity())
        plans = QualificationPlan.query.filter_by(user_id=user_id).all()

        return {
            'plans': [
                {
                    'id': p.id,
                    'uuid': p.uuid,
                    'name': p.plan_name,
                    'description': p.description,
                    'status': p.status,
                    'progress': p.progress_percentage,
                    'planned_start_date': p.planned_start_date.isoformat() if p.planned_start_date else None,
                    'planned_end_date': p.planned_end_date.isoformat() if p.planned_end_date else None,
                    'estimated_duration_weeks': p.estimated_duration_weeks,
                    'created_at': p.created_at.isoformat() if p.created_at else None
                } for p in plans
            ]
        }
    except Exception as e:
        return {'error': str(e)}, 500

@main_bp.route('/qualification-plans', methods=['POST'])
@jwt_required()
def create_qualification_plan():
    """Create new qualification plan"""
    try:
        user_id = int(get_jwt_identity())
        data = request.get_json()

        plan = QualificationPlan(
            user_id=user_id,
            plan_name=data.get('name'),
            description=data.get('description'),
            target_role_id=data.get('target_role_id'),
            selected_archetype_id=data.get('archetype_id'),
            assessment_id=data.get('assessment_id'),
            planned_start_date=datetime.fromisoformat(data['planned_start_date']) if data.get('planned_start_date') else None,
            planned_end_date=datetime.fromisoformat(data['planned_end_date']) if data.get('planned_end_date') else None,
            estimated_duration_weeks=data.get('estimated_duration_weeks'),
            learning_objectives=data.get('learning_objectives', []),
            selected_modules=data.get('selected_modules', []),
            learning_formats=data.get('learning_formats', {}),
            resource_requirements=data.get('resource_requirements', {})
        )

        db.session.add(plan)
        db.session.commit()

        return {
            'message': 'Qualification plan created successfully',
            'plan': {
                'id': plan.id,
                'uuid': plan.uuid,
                'name': plan.plan_name
            }
        }
    except Exception as e:
        db.session.rollback()
        return {'error': str(e)}, 500

# Company Context Endpoints
@main_bp.route('/company-context', methods=['POST'])
@jwt_required()
def create_company_context():
    """Create or update company context for RAG generation"""
    try:
        data = request.get_json()

        context = CompanyContext(
            company_name=data.get('company_name'),
            industry_domain=data.get('industry_domain'),
            business_domain=data.get('business_domain'),
            processes=data.get('processes', []),
            methods=data.get('methods', []),
            tools=data.get('tools', []),
            se_maturity_level=data.get('se_maturity_level'),
            organizational_size=data.get('organizational_size'),
            current_challenges=data.get('current_challenges', []),
            regulatory_requirements=data.get('regulatory_requirements', []),
            learning_preferences=data.get('learning_preferences', []),
            available_resources=data.get('available_resources', {}),
            extraction_method='manual'
        )

        db.session.add(context)
        db.session.commit()

        return {
            'message': 'Company context created successfully',
            'context': {
                'id': context.id,
                'uuid': context.uuid,
                'company_name': context.company_name
            }
        }
    except Exception as e:
        db.session.rollback()
        return {'error': str(e)}, 500

# Learning Objectives Endpoints
@main_bp.route('/learning-objectives', methods=['GET'])
@jwt_required()
def get_learning_objectives():
    """Get learning objectives with optional filtering"""
    try:
        # Query parameters
        competency_id = request.args.get('competency_id', type=int)
        archetype_id = request.args.get('archetype_id', type=int)
        company_context_id = request.args.get('company_context_id', type=int)

        query = LearningObjective.query

        if competency_id:
            query = query.filter_by(competency_id=competency_id)
        if archetype_id:
            query = query.filter_by(archetype_id=archetype_id)
        if company_context_id:
            query = query.filter_by(company_context_id=company_context_id)

        objectives = query.all()

        return {
            'objectives': [
                {
                    'id': obj.id,
                    'uuid': obj.uuid,
                    'objective_text': obj.objective_text,
                    'competency_name': obj.competency.name if obj.competency else None,
                    'archetype_name': obj.archetype.name if obj.archetype else None,
                    'target_role_name': obj.target_role.name if obj.target_role else None,
                    'quality_score': obj.quality_score,
                    'smart_score': obj.smart_score,
                    'meets_threshold': obj.meets_threshold,
                    'status': obj.status,
                    'generated_at': obj.generated_at.isoformat() if obj.generated_at else None
                } for obj in objectives
            ]
        }
    except Exception as e:
        return {'error': str(e)}, 500

# System Status Endpoints
@main_bp.route('/system/status', methods=['GET'])
def get_system_status():
    """Get comprehensive system status"""
    try:
        # Database connectivity check
        db_status = 'connected'
        try:
            db.session.execute('SELECT 1')
        except:
            db_status = 'disconnected'

        # Component counts
        total_users = User.query.count()
        total_assessments = Assessment.query.count()
        total_objectives = LearningObjective.query.count()
        total_plans = QualificationPlan.query.count()

        # Recent activity
        recent_assessments = Assessment.query.filter(
            Assessment.created_at >= datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
        ).count()

        return {
            'status': 'operational',
            'timestamp': datetime.utcnow().isoformat(),
            'database': {
                'status': db_status,
                'total_users': total_users,
                'total_assessments': total_assessments,
                'total_objectives': total_objectives,
                'total_plans': total_plans
            },
            'activity': {
                'assessments_today': recent_assessments
            },
            'components': {
                'marcel_framework': 'operational',
                'derik_assessor': 'integrated',
                'rag_llm_innovation': 'operational',
                'frontend': 'ready'
            }
        }
    except Exception as e:
        return {
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }, 500

# User Response Endpoints
@main_bp.route('/users/<int:user_id>/responses', methods=['GET'])
@jwt_required()
def get_user_responses(user_id):
    """Get user's questionnaire responses"""
    try:
        # Verify user access (users can only access their own responses)
        current_user_id = int(get_jwt_identity())
        if current_user_id != user_id:
            return {'error': 'Unauthorized access to user responses'}, 403

        # Get user's assessment responses
        assessments = Assessment.query.filter_by(user_id=user_id).all()

        responses = []
        for assessment in assessments:
            if assessment.results:
                responses.append({
                    'assessment_id': assessment.id,
                    'assessment_uuid': assessment.uuid,
                    'assessment_type': assessment.assessment_type,
                    'phase': assessment.phase,
                    'responses': assessment.results,
                    'completed_at': assessment.completed_at.isoformat() if assessment.completed_at else None
                })

        return {
            'user_id': user_id,
            'responses': responses,
            'total_assessments': len(responses)
        }

    except Exception as e:
        return {'error': str(e)}, 500


# Error handlers
@main_bp.errorhandler(400)
def bad_request(error):
    return {'error': 'Bad request', 'message': str(error)}, 400

@main_bp.errorhandler(401)
def unauthorized(error):
    return {'error': 'Unauthorized', 'message': 'Authentication required'}, 401

@main_bp.errorhandler(403)
def forbidden(error):
    return {'error': 'Forbidden', 'message': 'Insufficient permissions'}, 403

@main_bp.errorhandler(500)
def internal_error(error):
    db.session.rollback()
    return {'error': 'Internal server error'}, 500


# =============================================================================
# MVP SIMPLIFIED API ROUTES (merged into main_bp)
# =============================================================================

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def _initialize_organization_matrices(new_org_id):
    """
    Initialize a new organization with default role-process matrix and CALCULATE role-competency matrix.
    Copies role-process from organization_id=1 (default/template organization).
    Then CALCULATES role-competency matrix using update_role_competency_matrix stored procedure.

    FIXED BUG: Previously copied role-competency from org 1, which would propagate bad data.
    NOW: Always calculates fresh values from role-process × process-competency.

    Uses Derik's stored procedures:
    - insert_new_org_default_role_process_matrix (copies from org 1)
    - update_role_competency_matrix (calculates from matrices)

    Source: sesurveyapp-main/postgres-init/init.sql lines 251-292, 393-432
    """
    from sqlalchemy import text

    try:
        # 1. Copy role-process matrix from org 1 (always succeeds - we have 420 entries: 14 roles × 30 processes)
        db.session.execute(
            text('CALL insert_new_org_default_role_process_matrix(:org_id);'),
            {'org_id': new_org_id}
        )
        current_app.logger.info(f"[OK] Copied 420 role-process matrix entries for org {new_org_id}")

        # 2. CALCULATE role-competency matrix (don't copy - always calculate fresh!)
        # This ensures correct values even if org 1 has bad data
        try:
            db.session.execute(
                text('CALL update_role_competency_matrix(:org_id);'),
                {'org_id': new_org_id}
            )
            current_app.logger.info(f"[OK] Calculated role-competency matrix for org {new_org_id} (from role-process × process-competency)")
        except Exception as calc_error:
            # This might fail if process_competency_matrix is empty, but that's OK
            current_app.logger.warning(f"[SKIP] Role-competency calculation failed (process-competency matrix may be empty): {calc_error}")

        return True

    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to initialize matrices for org {new_org_id}: {e}")
        # Don't fail the registration - org can configure manually later
        return False


# =============================================================================
# AUTHENTICATION ENDPOINTS (4 endpoints)
# =============================================================================

@main_bp.route('/mvp/auth/login', methods=['POST'])
def login():
    """Login for both admin and employee users"""
    try:
        data = request.get_json()
        username = data.get('username')
        password = data.get('password')

        if not username or not password:
            return jsonify({'error': 'Username and password required'}), 400

        # Find user in MVP users table
        user = User.query.filter_by(username=username).first()

        if user and user.check_password(password):
            # Update last login
            user.last_login = datetime.utcnow()
            db.session.commit()

            # Create access token
            access_token = create_access_token(
                identity=str(user.id),
                additional_claims={
                    'organization_id': user.organization_id,
                    'role': user.role
                }
            )

            # Fetch organization details
            response_data = {
                'access_token': access_token,
                'user': user.to_dict()
            }

            # Include organization details if user belongs to one
            if user.organization_id:
                org = Organization.query.get(user.organization_id)
                if org:
                    response_data['organization'] = org.to_dict()

            return jsonify(response_data), 200

        return jsonify({'error': 'Invalid credentials'}), 401

    except Exception as e:
        current_app.logger.error(f"Login error: {str(e)}")
        return jsonify({'error': 'Login failed'}), 500


@main_bp.route('/mvp/auth/register-admin', methods=['POST'])
def register_admin():
    """Admin creates organization and becomes first user"""
    try:
        data = request.get_json()
        current_app.logger.info(f"[ADMIN REGISTRATION] Received data: {data}")

        # Required fields
        required_fields = ['username', 'password', 'organization_name', 'organization_size']
        for field in required_fields:
            if not data.get(field):
                error_msg = f'{field} is required'
                current_app.logger.error(f"[ADMIN REGISTRATION] Validation failed: {error_msg}")
                return jsonify({'error': error_msg}), 400

        # Check if username already exists
        if User.query.filter_by(username=data['username']).first():
            error_msg = 'Username already registered'
            current_app.logger.error(f"[ADMIN REGISTRATION] Username conflict: {data['username']}")
            return jsonify({'error': error_msg}), 400

        # Create organization (using Derik's unified model)
        org_code = Organization.generate_public_key(data['organization_name'])
        organization = Organization(
            organization_name=data['organization_name'],
            organization_public_key=org_code,
            size=data['organization_size']
        )
        db.session.add(organization)
        db.session.flush()  # Get organization ID

        # MATRICES NO LONGER AUTO-INITIALIZED AT REGISTRATION
        # Matrix initialization now happens in Phase 1 Task 2 (Role Selection)
        # - User defines organization roles (cluster-mapped or custom)
        # - Matrix is auto-created with values from org 1 for standard roles
        # - Custom roles initialized with zeros
        # - User edits and validates with RACI rules before proceeding
        # _initialize_organization_matrices(organization.id)
        # current_app.logger.info(f"[ADMIN REGISTRATION] Initialized default matrices for org {organization.id}")
        current_app.logger.info(f"[ADMIN REGISTRATION] Organization {organization.id} created - matrices will be initialized in Phase 1 Task 2")

        # Create admin user
        admin_user = User(
            username=data['username'],
            first_name=data.get('first_name'),  # Optional
            last_name=data.get('last_name'),    # Optional
            role='admin',
            organization_id=organization.id,
            joined_via_code=org_code
        )
        admin_user.set_password(data['password'])
        db.session.add(admin_user)
        db.session.commit()

        # Create access token
        access_token = create_access_token(
            identity=str(admin_user.id),
            additional_claims={
                'organization_id': organization.id,
                'role': 'admin'
            }
        )

        return jsonify({
            'access_token': access_token,
            'user': admin_user.to_dict(),
            'organization': organization.to_dict(),
            'organization_code': org_code
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Admin registration error: {str(e)}")
        return jsonify({'error': 'Registration failed'}), 500


@main_bp.route('/mvp/auth/register-employee', methods=['POST'])
def register_employee():
    """Employee joins organization with organization code"""
    try:
        data = request.get_json()

        # Required fields
        required_fields = ['username', 'password', 'organization_code']
        for field in required_fields:
            if not data.get(field):
                return jsonify({'error': f'{field} is required'}), 400

        # Check if username already exists
        if User.query.filter_by(username=data['username']).first():
            return jsonify({'error': 'Username already registered'}), 400

        # Validate organization code (using Derik's organization_public_key field)
        organization = Organization.query.filter_by(
            organization_public_key=data['organization_code'].upper()
        ).first()

        if not organization:
            return jsonify({'error': 'Invalid organization code'}), 400

        # Create employee user
        employee_user = User(
            username=data['username'],
            first_name=data.get('first_name'),  # Optional
            last_name=data.get('last_name'),    # Optional
            role='employee',
            organization_id=organization.id,
            joined_via_code=data['organization_code'].upper()
        )
        employee_user.set_password(data['password'])
        db.session.add(employee_user)
        db.session.commit()

        # Create access token
        access_token = create_access_token(
            identity=str(employee_user.id),
            additional_claims={
                'organization_id': organization.id,
                'role': 'employee'
            }
        )

        return jsonify({
            'access_token': access_token,
            'user': employee_user.to_dict(),
            'organization': organization.to_dict()
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Employee registration error: {str(e)}")
        return jsonify({'error': 'Registration failed'}), 500


@main_bp.route('/auth/me', methods=['GET'])
@jwt_required()
def get_current_user():
    """Get current user information"""
    try:
        user_id = int(get_jwt_identity())
        user = User.query.get(user_id)

        if not user:
            return jsonify({'error': 'User not found'}), 404

        return jsonify({'user': user.to_dict()}), 200

    except Exception as e:
        current_app.logger.error(f"Get current user error: {str(e)}")
        return jsonify({'error': 'Failed to get user info'}), 500

@main_bp.route('/auth/verify', methods=['GET'])
@jwt_required()
def verify_auth():
    """Verify JWT token and return user info (compatibility endpoint)"""
    try:
        user_id = int(get_jwt_identity())
        user = User.query.get(user_id)

        if not user:
            return jsonify({'error': 'User not found'}), 404

        return jsonify({'user': user.to_dict()}), 200

    except Exception as e:
        current_app.logger.error(f"Auth verification error: {str(e)}")
        return jsonify({'error': 'Token verification failed'}), 401

@main_bp.route('/mvp/auth/logout', methods=['POST'])
def logout():
    """Logout endpoint (for MVP - since JWT tokens are stateless, this is mainly for client-side cleanup)"""
    try:
        # For JWT tokens, logout is mainly handled client-side
        # Server-side logout would require token blacklisting which is not implemented in MVP
        return jsonify({'message': 'Logged out successfully'}), 200
    except Exception as e:
        current_app.logger.error(f"Logout error: {str(e)}")
        return jsonify({'error': 'Logout failed'}), 500


# =============================================================================
# ORGANIZATION MANAGEMENT ENDPOINTS (3 endpoints)
# =============================================================================

@main_bp.route('/organization/setup', methods=['POST'])
@jwt_required()
def organization_setup():
    """Update organization details (Admin only)"""
    try:
        user_id = int(get_jwt_identity())
        claims = get_jwt()

        if claims.get('role') != 'admin':
            return jsonify({'error': 'Admin access required'}), 403

        user = User.query.get(user_id)
        organization = Organization.query.get(user.organization_id)

        if not organization:
            return jsonify({'error': 'Organization not found'}), 404

        data = request.get_json()

        # Update organization details (using Derik's field names)
        if 'name' in data:
            organization.organization_name = data['name']
        if 'size' in data:
            organization.size = data['size']

        db.session.commit()

        return jsonify({'organization': organization.to_dict()}), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Organization setup error: {str(e)}")
        return jsonify({'error': 'Organization setup failed'}), 500


@main_bp.route('/organization/verify-code/<code>', methods=['GET'])
def verify_organization_code(code):
    """Verify organization code for employee registration"""
    try:
        organization = Organization.query.filter_by(organization_public_key=code.upper()).first()

        if organization:
            return jsonify({
                'valid': True,
                'organization_name': organization.organization_name
            }), 200
        else:
            return jsonify({
                'valid': False,
                'organization_name': None
            }), 200

    except Exception as e:
        current_app.logger.error(f"Organization verification error: {str(e)}")
        return jsonify({'error': 'Verification failed'}), 500


@main_bp.route('/organization/dashboard', methods=['GET'])
def organization_dashboard():
    """Get organization dashboard data - supports both JWT and query param authentication"""
    print("=" * 80)
    print("ORGANIZATION DASHBOARD ENDPOINT HIT!")
    print("=" * 80)
    sys.stdout.flush()
    try:
        # Try to get user from JWT token
        auth_header = request.headers.get('Authorization')
        user_id = None
        user = None
        organization = None

        print(f"DEBUG: Authorization header: {auth_header}")
        sys.stdout.flush()

        if auth_header and auth_header.startswith('Bearer '):
            # Try JWT authentication
            try:
                from flask_jwt_extended import verify_jwt_in_request
                verify_jwt_in_request(optional=True)
                user_id = int(get_jwt_identity())
                if user_id:
                    claims = get_jwt()
                    print(f"DEBUG: User ID from JWT: {user_id}, Role: {claims.get('role')}")
                    current_app.logger.info(f"DEBUG: Organization dashboard requested by user {user_id}, role: {claims.get('role')}")
                    user = User.query.get(user_id)
                    if user:
                        organization = Organization.query.get(user.organization_id)
            except Exception as jwt_error:
                print(f"DEBUG: JWT verification failed: {jwt_error}")
                # Continue to query param fallback

        # If no JWT or JWT failed, try query parameters
        if not organization:
            org_code = request.args.get('code')
            org_id = request.args.get('id')

            print(f"DEBUG: Using query params - code: {org_code}, id: {org_id}")
            sys.stdout.flush()

            if org_code:
                organization = Organization.query.filter_by(organization_public_key=org_code).first()
            elif org_id:
                organization = Organization.query.get(int(org_id))

        current_app.logger.info(f"DEBUG: Found user: {user.username if user else 'None'}")
        current_app.logger.info(f"DEBUG: Organization ID: {user.organization_id if user else 'None'}")
        current_app.logger.info(f"DEBUG: Organization: {organization.organization_name if organization else 'None'}")

        if not organization:
            return jsonify({'error': 'Organization not found'}), 404

        # Get organization statistics
        total_users = User.query.filter_by(organization_id=organization.id).count()

        # Get completed assessments - use proper join with select_from
        try:
            completed_assessments = db.session.query(CompetencyAssessment).select_from(User).join(
                CompetencyAssessment, User.id == CompetencyAssessment.user_id
            ).filter(
                User.organization_id == organization.id
            ).count()
        except Exception as e:
            print(f"DEBUG: Completed assessments query failed: {e}")
            completed_assessments = 0

        # REMOVED Phase 2A: MaturityAssessment model deleted - data now comes from questionnaire system
        # maturity_assessment = MaturityAssessment.query.filter_by(organization_id=organization.id).first()

        # BRIDGE: Check questionnaire system for Phase 1 assessment data
        questionnaire_maturity_data = None
        selected_archetype = organization.selected_archetype  # Default fallback

        try:
            # Import questionnaire models to check for completed assessments
            from models import QuestionnaireResponse, Questionnaire

            current_app.logger.info(f"DEBUG: Starting bridge check for organization {organization.id}")

            # Find admin users in this organization who completed Phase 1
            admin_users = User.query.filter_by(
                organization_id=organization.id,
                role='admin'
            ).all()

            current_app.logger.info(f"DEBUG: Found {len(admin_users)} admin users in organization")

            for admin_user in admin_users:
                current_app.logger.info(f"DEBUG: Checking admin user {admin_user.id} ({admin_user.username})")

                # Check for completed maturity assessment (questionnaire ID 1)
                # ORDER BY completed_at DESC to get the LATEST assessment
                maturity_response = QuestionnaireResponse.query.filter_by(
                    user_id=str(admin_user.id),
                    questionnaire_id=1,
                    status='completed'
                ).order_by(QuestionnaireResponse.completed_at.desc()).first()

                current_app.logger.info(f"DEBUG: Maturity response found: {maturity_response is not None}")
                if maturity_response:
                    current_app.logger.info(f"DEBUG: Maturity score: {maturity_response.total_score}/{maturity_response.max_possible_score} (completed: {maturity_response.completed_at})")

                # Check for completed archetype selection (questionnaire ID 2)
                # ORDER BY completed_at DESC to get the LATEST archetype selection
                archetype_response = QuestionnaireResponse.query.filter_by(
                    user_id=str(admin_user.id),
                    questionnaire_id=2,
                    status='completed'
                ).order_by(QuestionnaireResponse.completed_at.desc()).first()

                current_app.logger.info(f"DEBUG: Archetype response found: {archetype_response is not None}")

                if maturity_response and archetype_response:
                    current_app.logger.info(f"DEBUG: Found both responses! Creating bridge data...")

                    # CRITICAL: Extract computed archetype from questionnaire response (including secondary)
                    secondary_archetype = None
                    if archetype_response.computed_archetype:
                        try:
                            import json
                            computed_data = json.loads(archetype_response.computed_archetype)
                            selected_archetype = computed_data.get('name', selected_archetype)
                            secondary_archetype = computed_data.get('secondary')  # Extract secondary archetype
                            current_app.logger.info(f"DEBUG: Extracted archetype from computed data: {selected_archetype}, secondary: {secondary_archetype}")
                        except json.JSONDecodeError as e:
                            current_app.logger.error(f"DEBUG: Failed to parse computed_archetype JSON: {e}")
                    else:
                        current_app.logger.warning(f"DEBUG: No computed_archetype data found in archetype response")

                    # Create maturity assessment data from questionnaire responses
                    # Use archetype_response.completed_at for accurate timestamp
                    questionnaire_maturity_data = {
                        'id': maturity_response.uuid,
                        'organization_id': organization.id,
                        'overall_score': maturity_response.total_score / maturity_response.max_possible_score * 5.0 if maturity_response.max_possible_score > 0 else 0,
                        'scope_score': 2.5,  # Default - could be calculated from specific questions
                        'process_score': 2.5,  # Default - could be calculated from specific questions
                        'overall_maturity': get_maturity_level_from_score(maturity_response.total_score / maturity_response.max_possible_score * 5.0 if maturity_response.max_possible_score > 0 else 0),
                        'completed_at': archetype_response.completed_at.isoformat() if archetype_response.completed_at else None,  # Use archetype completion time
                        'responses': None,
                        'secondary_archetype': secondary_archetype  # Include secondary archetype
                    }
                    current_app.logger.info(f"DEBUG: Bridge data created with score: {questionnaire_maturity_data['overall_score']}, archetype: {selected_archetype}, secondary: {secondary_archetype}")
                    break  # Use first completed assessment found

        except ImportError as e:
            current_app.logger.warning(f"Could not import questionnaire models: {e}")
        except Exception as e:
            current_app.logger.error(f"Error checking questionnaire system: {e}")
            import traceback
            current_app.logger.error(f"Traceback: {traceback.format_exc()}")

        # Use questionnaire data (MaturityAssessment model was removed in Phase 2A)
        final_maturity_assessment = questionnaire_maturity_data

        # Extract secondary archetype from questionnaire data if available
        final_secondary_archetype = questionnaire_maturity_data.get('secondary_archetype') if questionnaire_maturity_data else None

        # Log the timestamps being sent
        if final_maturity_assessment:
            current_app.logger.info(f"DEBUG: Sending completion timestamp: {final_maturity_assessment.get('completed_at')}")

        dashboard_data = {
            'organization': {
                **organization.to_dict(),
                'selected_archetype': selected_archetype,
                'secondary_archetype': final_secondary_archetype  # Include secondary archetype
            },
            'statistics': {
                'total_users': total_users,
                'completed_assessments': completed_assessments,
                'maturity_completed': final_maturity_assessment is not None
            },
            'maturity_assessment': final_maturity_assessment
        }

        return jsonify(dashboard_data), 200

    except Exception as e:
        current_app.logger.error(f"Organization dashboard error: {str(e)}")
        return jsonify({'error': 'Failed to load dashboard'}), 500


def get_maturity_level_from_score(score):
    """Convert maturity score to level name"""
    if score >= 4.0:
        return 'Optimizing'
    elif score >= 3.0:
        return 'Defined'
    elif score >= 2.0:
        return 'Managed'
    elif score >= 1.0:
        return 'Performed'
    else:
        return 'Initial'


@main_bp.route('/organization/archetype', methods=['PUT'])
@jwt_required()
def update_organization_archetype():
    """Update organization's selected archetype (Admin only)"""
    try:
        user_id = int(get_jwt_identity())
        claims = get_jwt()

        if claims.get('role') != 'admin':
            return jsonify({'error': 'Admin access required'}), 403

        user = User.query.get(user_id)
        organization = Organization.query.get(user.organization_id)

        if not organization:
            return jsonify({'error': 'Organization not found'}), 404

        data = request.get_json()
        archetype = data.get('selected_archetype')

        if not archetype:
            return jsonify({'error': 'selected_archetype is required'}), 400

        organization.selected_archetype = archetype
        db.session.commit()

        return jsonify({'organization': organization.to_dict()}), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Update archetype error: {str(e)}")
        return jsonify({'error': 'Failed to update archetype'}), 500


@main_bp.route('/organization/phase1-complete', methods=['PUT'])
@jwt_required()
def complete_phase1():
    """Mark Phase 1 as complete for organization (Admin only)"""
    try:
        user_id = int(get_jwt_identity())
        claims = get_jwt()

        if claims.get('role') != 'admin':
            return jsonify({'error': 'Admin access required'}), 403

        user = User.query.get(user_id)
        organization = Organization.query.get(user.organization_id)

        if not organization:
            return jsonify({'error': 'Organization not found'}), 404

        data = request.get_json()
        maturity_score = data.get('maturity_score')
        selected_archetype = data.get('selected_archetype')

        # Update organization with Phase 1 completion data
        if maturity_score is not None:
            organization.maturity_score = maturity_score
        if selected_archetype:
            organization.selected_archetype = selected_archetype

        organization.phase1_completed = True
        db.session.commit()

        current_app.logger.info(f"Phase 1 completed for organization {organization.id}")
        return jsonify({'organization': organization.to_dict()}), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Phase 1 completion error: {str(e)}")
        return jsonify({'error': 'Failed to mark Phase 1 as complete'}), 500


# =============================================================================
# ASSESSMENT ENDPOINTS (3 endpoints)
# NOTE: Maturity assessment is handled by questionnaire system (questionnaire ID 1)
#       Archetype selection is handled by /api/seqpt/phase1/archetype-selection
# =============================================================================

@main_bp.route('/assessments/competency', methods=['POST'])
@jwt_required()
def submit_competency_assessment():
    """Submit individual competency assessment (All users)"""
    try:
        user_id = int(get_jwt_identity())
        data = request.get_json()

        # Validate competency scores
        competency_scores = data.get('competency_scores')
        if not competency_scores:
            return jsonify({'error': 'competency_scores required'}), 400

        # Create competency assessment record
        assessment = CompetencyAssessment(
            user_id=user_id,
            role_cluster=data.get('role_cluster', 'Unknown')
        )
        assessment.set_competency_scores(competency_scores)
        db.session.add(assessment)
        db.session.commit()

        return jsonify({'assessment': assessment.to_dict()}), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Competency assessment error: {str(e)}")
        return jsonify({'error': 'Failed to submit assessment'}), 500


@main_bp.route('/assessments/results/<user_id>', methods=['GET'])
@jwt_required()
def get_user_assessment_results_legacy(user_id):
    """Get assessment results for a user (legacy endpoint)"""
    try:
        current_user_id = int(get_jwt_identity())
        claims = get_jwt()

        # Users can only see their own results, admins can see all
        if user_id != current_user_id and claims.get('role') != 'admin':
            return jsonify({'error': 'Access denied'}), 403

        # Get competency assessment
        competency_assessment = CompetencyAssessment.query.filter_by(
            user_id=user_id
        ).first()

        # Get role mapping
        role_mapping = RoleMapping.query.filter_by(user_id=user_id).first()

        # Get learning plan
        learning_plan = LearningPlan.query.filter_by(user_id=user_id).first()

        results = {
            'competency_assessment': competency_assessment.to_dict() if competency_assessment else None,
            'role_mapping': role_mapping.to_dict() if role_mapping else None,
            'learning_plan': learning_plan.to_dict() if learning_plan else None
        }

        return jsonify(results), 200

    except Exception as e:
        current_app.logger.error(f"Get assessment results error: {str(e)}")
        return jsonify({'error': 'Failed to get results'}), 500


@main_bp.route('/assessments/organization-summary', methods=['GET'])
@jwt_required()
def get_organization_assessment_summary():
    """Get organization-wide assessment summary (Admin only)"""
    try:
        user_id = int(get_jwt_identity())
        claims = get_jwt()

        if claims.get('role') != 'admin':
            return jsonify({'error': 'Admin access required'}), 403

        user = User.query.get(user_id)

        # Get all users in organization
        org_users = User.query.filter_by(organization_id=user.organization_id).all()

        # Get completion statistics
        total_users = len(org_users)
        completed_competency = CompetencyAssessment.query.join(User).filter(
            User.organization_id == user.organization_id
        ).count()

        # REMOVED Phase 2A: MaturityAssessment model deleted - data comes from questionnaire system
        # maturity_assessment = MaturityAssessment.query.filter_by(organization_id=user.organization_id).first()

        summary = {
            'total_users': total_users,
            'completed_competency_assessments': completed_competency,
            'completion_rate': (completed_competency / total_users * 100) if total_users > 0 else 0,
            'maturity_assessment': None  # MaturityAssessment removed - use dashboard endpoint for full data
        }

        return jsonify(summary), 200

    except Exception as e:
        current_app.logger.error(f"Organization summary error: {str(e)}")
        return jsonify({'error': 'Failed to get summary'}), 500


# =============================================================================
# LEARNING PLAN ENDPOINTS (2 endpoints)
# =============================================================================

@main_bp.route('/learning-plan/<user_id>', methods=['GET'])
@jwt_required()
def get_learning_plan(user_id):
    """Get learning plan for a user"""
    try:
        current_user_id = int(get_jwt_identity())
        claims = get_jwt()

        # Users can only see their own plan, admins can see all
        if user_id != current_user_id and claims.get('role') != 'admin':
            return jsonify({'error': 'Access denied'}), 403

        learning_plan = LearningPlan.query.filter_by(user_id=user_id).first()

        if not learning_plan:
            return jsonify({'error': 'Learning plan not found'}), 404

        return jsonify({'learning_plan': learning_plan.to_dict()}), 200

    except Exception as e:
        current_app.logger.error(f"Get learning plan error: {str(e)}")
        return jsonify({'error': 'Failed to get learning plan'}), 500


@main_bp.route('/learning-plan/generate', methods=['POST'])
@jwt_required()
def generate_learning_plan():
    """Generate learning plan for current user"""
    try:
        user_id = int(get_jwt_identity())
        data = request.get_json()

        # Get user's competency assessment
        competency_assessment = CompetencyAssessment.query.filter_by(
            user_id=user_id
        ).first()

        if not competency_assessment:
            return jsonify({'error': 'Competency assessment required first'}), 400

        # Get organization's selected archetype
        user = User.query.get(user_id)
        organization = Organization.query.get(user.organization_id)

        archetype = data.get('archetype') or organization.selected_archetype
        if not archetype:
            return jsonify({'error': 'No archetype available'}), 400

        # Generate learning plan using templates
        templates = generate_learning_plan_templates()
        objectives = templates.get(archetype, [])
        recommended_modules = generate_basic_modules(archetype)

        # Create or update learning plan
        learning_plan = LearningPlan.query.filter_by(user_id=user_id).first()
        if not learning_plan:
            learning_plan = LearningPlan(user_id=user_id)
            db.session.add(learning_plan)

        learning_plan.set_objectives(objectives)
        learning_plan.set_recommended_modules(recommended_modules)
        learning_plan.estimated_duration_weeks = len(objectives) * 2  # 2 weeks per objective
        learning_plan.archetype_used = archetype

        db.session.commit()

        return jsonify({'learning_plan': learning_plan.to_dict()}), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Generate learning plan error: {str(e)}")
        return jsonify({'error': 'Failed to generate learning plan'}), 500


# =============================================================================
# QUESTIONNAIRE COMPATIBILITY ENDPOINTS
# =============================================================================

@main_bp.route('/public/users/<string:user_id>/responses', methods=['GET'])
def get_user_questionnaire_responses_uuid(user_id):
    """Public endpoint for questionnaire responses using UUID user IDs (compatibility)"""
    try:
        # Import the models from models.py to avoid circular imports
        from models import QuestionnaireResponse, Questionnaire, User

        import sys
        debug_msg = f"DEBUG: MVP public endpoint accessed for user UUID {user_id}"
        print(debug_msg)
        sys.stdout.flush()

        # CRITICAL: The questionnaire system uses integer User IDs, not UUIDs
        # We need to find the User by UUID first, then query responses by integer ID
        user = User.query.filter_by(uuid=user_id).first()

        if not user:
            debug_msg = f"DEBUG: No user found with UUID {user_id}"
            print(debug_msg)
            sys.stdout.flush()
            return jsonify({
                'success': True,
                'responses': [],
                'total_count': 0
            }), 200

        debug_msg = f"DEBUG: Found user ID {user.id} for UUID {user_id}"
        print(debug_msg)
        sys.stdout.flush()

        # Query responses using the integer user ID
        responses = QuestionnaireResponse.query.filter_by(user_id=user.id).order_by(QuestionnaireResponse.started_at.desc()).all()

        debug_msg = f"DEBUG: Found {len(responses)} responses for user ID {user.id}"
        print(debug_msg)
        sys.stdout.flush()

        responses_data = []
        for response in responses:
            questionnaire_name = 'Unknown Questionnaire'
            questionnaire_type = 'unknown'

            if response.questionnaire:
                questionnaire_name = response.questionnaire.name
                questionnaire_type = response.questionnaire.questionnaire_type

            responses_data.append({
                'uuid': response.uuid,
                'questionnaire_id': response.questionnaire_id,
                'questionnaire_name': questionnaire_name,
                'questionnaire_type': questionnaire_type,
                'started_at': response.started_at.isoformat() if response.started_at else None,
                'completed_at': response.completed_at.isoformat() if response.completed_at else None,
                'status': response.status,
                'is_completed': response.status == 'completed',
                'phase_name': getattr(response, 'phase_name', None),
                'current_score': getattr(response, 'total_score', None),
                'max_score': getattr(response, 'max_possible_score', None),
                'completion_percentage': response.completion_percentage if response.completion_percentage else 0.0
            })

        debug_msg = f"DEBUG: MVP endpoint returning {len(responses_data)} responses for user {user_id}"
        print(debug_msg)
        sys.stdout.flush()

        return jsonify({
            'success': True,
            'responses': responses_data,
            'total_count': len(responses_data)
        }), 200

    except Exception as e:
        import traceback
        debug_msg = f"DEBUG: Error in MVP public endpoint: {str(e)}"
        print(debug_msg)
        print(f"Traceback: {traceback.format_exc()}")
        sys.stdout.flush()
        return jsonify({'error': 'Failed to get questionnaire responses'}), 500


# =============================================================================
# PHASE 1 API ENDPOINTS
# Maturity Assessment, Role Identification, Target Group, and Strategy Selection
# =============================================================================

@main_bp.route('/phase1/maturity/<int:org_id>/latest', methods=['GET'])
def get_latest_maturity_assessment(org_id):
    """Get latest maturity assessment for an organization"""
    try:
        from models import PhaseQuestionnaireResponse, Organization

        # Verify organization exists
        org = Organization.query.get(org_id)
        if not org:
            return jsonify({'error': 'Organization not found'}), 404

        # Get latest maturity assessment
        maturity = PhaseQuestionnaireResponse.query.filter_by(
            organization_id=org_id,
            questionnaire_type='maturity',
            phase=1
        ).order_by(PhaseQuestionnaireResponse.completed_at.desc()).first()

        if not maturity:
            return jsonify({
                'exists': False,
                'data': None
            }), 200

        # Get the responses which contain both answers and results
        response_data = maturity.get_responses()

        return jsonify({
            'exists': True,
            'data': {
                'id': maturity.id,
                'answers': response_data.get('answers', {}),
                'results': response_data.get('results', {}),
                'completed_at': maturity.completed_at.isoformat() if maturity.completed_at else None
            }
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting maturity assessment: {str(e)}")
        return jsonify({'error': 'Failed to get maturity assessment'}), 500


@main_bp.route('/phase1/maturity/save', methods=['POST'])
def save_maturity_assessment():
    """Save maturity assessment results"""
    try:
        from models import PhaseQuestionnaireResponse
        from flask_jwt_extended import verify_jwt_in_request

        data = request.get_json()

        org_id = data.get('org_id')
        answers = data.get('answers', {})
        results = data.get('results', {})

        if not org_id:
            return jsonify({'error': 'org_id is required'}), 400

        # Get user ID from JWT if available
        user_id = 1  # Default fallback
        try:
            verify_jwt_in_request(optional=True)
            jwt_user_id = get_jwt_identity()
            if jwt_user_id:
                user_id = int(jwt_user_id) if isinstance(jwt_user_id, str) else jwt_user_id
        except Exception:
            pass  # Use default user_id

        # Create new maturity assessment
        maturity = PhaseQuestionnaireResponse(
            organization_id=org_id,
            user_id=user_id,
            questionnaire_type='maturity',
            phase=1
        )

        # Store both answers and results together in the responses field
        maturity.set_responses({
            'answers': answers,
            'results': results
        })

        db.session.add(maturity)
        db.session.commit()

        return jsonify({
            'success': True,
            'id': maturity.id,
            'message': 'Maturity assessment saved successfully'
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error saving maturity assessment: {str(e)}")
        return jsonify({'error': 'Failed to save maturity assessment'}), 500


@main_bp.route('/phase1/roles/<int:org_id>/latest', methods=['GET'])
def get_latest_roles(org_id):
    """
    Get latest role identification for an organization.
    Returns roles directly from organization_roles table with database IDs.

    Refactored: 2025-10-30 - Now uses ORM instead of raw SQL
    """
    try:
        # Verify organization exists
        org = Organization.query.get(org_id)
        if not org:
            return jsonify({'error': 'Organization not found'}), 404

        # Fetch roles using ORM (with eager loading of standard_cluster relationship)
        roles = OrganizationRoles.query.filter_by(organization_id=org_id).order_by(OrganizationRoles.id).all()

        if not roles:
            return jsonify({
                'success': True,
                'exists': False,
                'data': None,
                'count': 0
            }), 200

        # Use built-in to_dict() method and add has_competencies flag
        roles_list = []
        for role in roles:
            role_dict = role.to_dict()

            # Check if role has any non-zero competencies
            # Query role_competency_matrix for this role
            has_competencies = db.session.query(RoleCompetencyMatrix).filter(
                RoleCompetencyMatrix.organization_id == org_id,
                RoleCompetencyMatrix.role_cluster_id == role.id,
                RoleCompetencyMatrix.role_competency_value > 0
            ).count() > 0

            role_dict['has_competencies'] = has_competencies
            roles_list.append(role_dict)

        return jsonify({
            'success': True,
            'exists': True,
            'data': roles_list,
            'count': len(roles_list),
            'organizationName': org.organization_name
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting roles: {str(e)}")
        return jsonify({'error': 'Failed to get roles'}), 500


@main_bp.route('/phase1/roles/save', methods=['POST'])
def save_roles():
    """
    Save identified SE roles for an organization to organization_roles table.
    Each role can be:
    - STANDARD: Maps to one of 14 standard role clusters
    - CUSTOM: User-defined role not mapped to any cluster

    Smart-merge feature (2025-10-30):
    - Detects pathway changes (Task 1 retake affecting seProcesses threshold)
    - Preserves matrix data for unchanged roles
    - Only resets matrix when pathway changes or user explicitly changes roles

    Refactored: 2025-10-30 - Now uses ORM instead of raw SQL
    """
    try:
        from models import PhaseQuestionnaireResponse
        from flask_jwt_extended import verify_jwt_in_request

        data = request.get_json()

        org_id = data.get('org_id')
        maturity_id = data.get('maturity_id')  # NEW: needed to detect pathway changes
        roles = data.get('roles', [])
        identification_method = data.get('identification_method', 'STANDARD')

        if not org_id:
            return jsonify({'error': 'org_id is required'}), 400

        # Get user ID from JWT if available
        user_id = 1  # Default fallback
        try:
            verify_jwt_in_request(optional=True)
            jwt_user_id = get_jwt_identity()
            if jwt_user_id:
                user_id = int(jwt_user_id) if isinstance(jwt_user_id, str) else jwt_user_id
        except Exception:
            pass  # Use default user_id

        # SMART-MERGE STEP 1: Detect pathway changes (Task 1 retake)
        MATURITY_THRESHOLD = 3  # "Defined and Established"
        pathway_changed = False
        old_pathway = None
        new_pathway = None

        if maturity_id:
            # Get the new maturity data
            new_maturity = PhaseQuestionnaireResponse.query.filter_by(
                id=maturity_id,
                organization_id=org_id,
                questionnaire_type='maturity'
            ).first()

            if new_maturity:
                new_results = new_maturity.get_computed_scores()
                new_se_processes = new_results.get('strategyInputs', {}).get('seProcessesValue', 0)
                new_pathway = 'STANDARD' if new_se_processes >= MATURITY_THRESHOLD else 'TASK_BASED'

                # Get the previous maturity (if exists)
                previous_maturity = PhaseQuestionnaireResponse.query.filter(
                    PhaseQuestionnaireResponse.organization_id == org_id,
                    PhaseQuestionnaireResponse.questionnaire_type == 'maturity',
                    PhaseQuestionnaireResponse.id != maturity_id
                ).order_by(PhaseQuestionnaireResponse.completed_at.desc()).first()

                if previous_maturity:
                    old_results = previous_maturity.get_computed_scores()
                    old_se_processes = old_results.get('strategyInputs', {}).get('seProcessesValue', 0)
                    old_pathway = 'STANDARD' if old_se_processes >= MATURITY_THRESHOLD else 'TASK_BASED'

                    # Pathway changed if crossing the threshold
                    if old_pathway != new_pathway:
                        pathway_changed = True
                        current_app.logger.warning(
                            f"[ROLE SAVE] Pathway changed for org {org_id}: {old_pathway} -> {new_pathway} "
                            f"(seProcesses: {old_se_processes} -> {new_se_processes})"
                        )

        # SMART-MERGE STEP 2: Check if organization already has roles using ORM
        existing_roles_objs = OrganizationRoles.query.filter_by(organization_id=org_id).all()

        # Convert to simple dicts for comparison
        existing_roles = [{
            'id': role.id,
            'name': role.role_name,
            'cluster': role.standard_role_cluster_id,
            'method': role.identification_method
        } for role in existing_roles_objs]

        # SMART-MERGE STEP 3: Compare submitted roles with existing roles to detect changes
        submitted_role_signatures = set()
        submitted_role_map = {}  # sig -> role data
        for role in roles:
            sig = f"{role.get('orgRoleName')}|{role.get('standardRoleId')}|{role.get('identificationMethod', 'STANDARD')}"
            submitted_role_signatures.add(sig)
            submitted_role_map[sig] = role

        existing_role_signatures = set()
        existing_role_map = {}  # sig -> role id
        for role in existing_roles:
            sig = f"{role['name']}|{role['cluster']}|{role['method']}"
            existing_role_signatures.add(sig)
            existing_role_map[sig] = role['id']

        is_new = len(existing_roles) == 0
        roles_changed = submitted_role_signatures != existing_role_signatures if not is_new else True

        # SMART-MERGE STEP 4: Build detailed change info
        unchanged_roles = submitted_role_signatures & existing_role_signatures
        added_roles = submitted_role_signatures - existing_role_signatures
        removed_roles = existing_role_signatures - submitted_role_signatures

        current_app.logger.info(
            f"[ROLE SAVE] Change analysis for org {org_id}: "
            f"unchanged={len(unchanged_roles)}, added={len(added_roles)}, removed={len(removed_roles)}, "
            f"pathway_changed={pathway_changed}"
        )

        if not is_new and not roles_changed:
            # CASE 1: Roles haven't changed - return existing roles (preserves matrix)
            current_app.logger.info(f"[ROLE SAVE] No role changes detected for org {org_id} - preserving matrix")

            # Use to_dict() for consistent output
            saved_roles = [role.to_dict() for role in existing_roles_objs]

            return jsonify({
                'success': True,
                'message': f'Using existing {len(saved_roles)} roles (no changes detected)',
                'roles': saved_roles,
                'count': len(saved_roles),
                'is_update': True,
                'roles_changed': False,
                'pathway_changed': False,
                'smart_merge_enabled': False
            }), 200

        elif not is_new and roles_changed:
            # CASE 2: Roles have changed
            if pathway_changed:
                # CASE 2a: Pathway changed (Task 1 retake) - FULL RESET
                current_app.logger.warning(
                    f"[ROLE SAVE] Pathway changed ({old_pathway} -> {new_pathway}) - FULL MATRIX RESET"
                )
                # Delete old roles using ORM (CASCADE will delete matrix)
                OrganizationRoles.query.filter_by(organization_id=org_id).delete()
                current_app.logger.warning(f"[ROLE SAVE] Deleted old roles and matrix (pathway change)")
                is_updating = True
                smart_merge_enabled = False

            else:
                # CASE 2b: Only roles changed (no pathway change) - SMART MERGE
                current_app.logger.info(
                    f"[ROLE SAVE] Roles changed but pathway stable - SMART MERGE: "
                    f"keep {len(unchanged_roles)}, add {len(added_roles)}, remove {len(removed_roles)}"
                )

                # Smart merge: Only delete removed roles
                if removed_roles:
                    removed_role_ids = [existing_role_map[sig] for sig in removed_roles]
                    OrganizationRoles.query.filter(
                        OrganizationRoles.organization_id == org_id,
                        OrganizationRoles.id.in_(removed_role_ids)
                    ).delete(synchronize_session=False)
                    current_app.logger.info(f"[ROLE SAVE] Deleted {len(removed_roles)} removed roles (matrix CASCADE)")

                is_updating = True
                smart_merge_enabled = True

        else:
            # CASE 3: New organization - first time setup
            current_app.logger.info(f"[ROLE SAVE] Creating new roles for org {org_id} (matrix will be initialized)")
            is_updating = False
            smart_merge_enabled = False

        # Insert/update roles into organization_roles table using ORM
        saved_roles = []
        roles_to_add = []  # Track which roles we're adding (for matrix initialization)

        for role in roles:
            # Extract role data
            role_name = role.get('orgRoleName')
            role_description = role.get('standard_role_description')
            standard_role_cluster_id = role.get('standardRoleId')  # NULL for custom roles
            role_identification_method = role.get('identificationMethod', 'STANDARD')
            participating = role.get('participatingInTraining', True)

            if not role_name:
                current_app.logger.warning(f"[ROLE SAVE] Skipping role with empty name for org {org_id}")
                continue

            # Build signature for this role
            sig = f"{role_name}|{standard_role_cluster_id}|{role_identification_method}"

            # SMART MERGE: Check if this role already exists (unchanged)
            if smart_merge_enabled and sig in unchanged_roles:
                # This role hasn't changed - reuse existing ID and preserve its matrix data
                existing_id = existing_role_map[sig]
                existing_obj = OrganizationRoles.query.get(existing_id)
                saved_roles.append(existing_obj.to_dict())
                current_app.logger.info(
                    f"[ROLE SAVE] Keeping unchanged role '{role_name}' (ID: {existing_id}) - matrix preserved"
                )
            else:
                # This is a new role (or full reset) - create it
                new_role = OrganizationRoles(
                    organization_id=org_id,
                    role_name=role_name,
                    role_description=role_description,
                    standard_role_cluster_id=standard_role_cluster_id,
                    identification_method=role_identification_method,
                    participating_in_training=participating
                )
                db.session.add(new_role)
                db.session.flush()  # Get the ID without committing

                # Use to_dict() for consistent output
                saved_role_dict = new_role.to_dict()
                saved_roles.append(saved_role_dict)
                roles_to_add.append(saved_role_dict)  # Track for matrix initialization

                current_app.logger.info(
                    f"[ROLE SAVE] {'Added' if smart_merge_enabled else 'Created'} role '{role_name}' (ID: {new_role.id}) "
                    f"for org {org_id} (cluster: {standard_role_cluster_id}, method: {role_identification_method})"
                )

        # Also save to PhaseQuestionnaireResponse for backward compatibility
        role_data = PhaseQuestionnaireResponse(
            organization_id=org_id,
            user_id=user_id,
            questionnaire_type='roles',
            phase=1
        )
        role_data.set_responses({
            'roles': saved_roles,
            'identification_method': identification_method
        })
        db.session.add(role_data)

        db.session.commit()

        # Build response message
        if smart_merge_enabled:
            message = (
                f"Smart merge: preserved {len(unchanged_roles)}, "
                f"added {len(added_roles)}, removed {len(removed_roles)} roles"
            )
        elif pathway_changed:
            message = f"Pathway changed - rebuilt {len(saved_roles)} roles (matrix reset)"
        else:
            message = f'{"Updated" if is_updating else "Created"} {len(saved_roles)} roles successfully'

        return jsonify({
            'success': True,
            'id': role_data.id,
            'message': message,
            'roles': saved_roles,
            'count': len(saved_roles),
            'is_update': is_updating,
            'roles_changed': roles_changed,
            'pathway_changed': pathway_changed,
            'smart_merge_enabled': smart_merge_enabled,
            'roles_to_add': roles_to_add,  # Only new roles that need matrix initialization
            'change_summary': {
                'unchanged': len(unchanged_roles),
                'added': len(added_roles),
                'removed': len(removed_roles)
            }
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"[ROLE SAVE ERROR] {str(e)}")
        import traceback
        current_app.logger.error(traceback.format_exc())
        return jsonify({'error': f'Failed to save roles: {str(e)}'}), 500


@main_bp.route('/phase1/roles/initialize-matrix', methods=['POST'])
def initialize_role_process_matrix():
    """
    Initialize role-process matrix for newly saved roles.

    For STANDARD roles (mapped to clusters):
        - Copy 30 process values from organization 1's reference matrix

    For CUSTOM roles (not mapped to clusters):
        - Initialize all 30 processes with value 0 (user must define)

    Smart-merge feature (2025-10-30):
        - If smart_merge=True: Only initialize matrix for new roles (preserves existing)
        - If smart_merge=False: Full reset (delete all and rebuild)

    This endpoint should be called after roles are saved to organization_roles.

    Refactored: 2025-10-30 - Now uses ORM instead of raw SQL
    """
    try:
        data = request.get_json()
        org_id = data.get('organization_id')
        roles = data.get('roles', [])  # Roles with database IDs
        smart_merge = data.get('smart_merge', False)  # NEW: smart merge flag

        if not org_id:
            return jsonify({'error': 'organization_id is required'}), 400

        if not roles:
            return jsonify({'error': 'roles array is required'}), 400

        # Smart merge: Only delete matrix for removed roles (already done by CASCADE)
        # Full reset: Delete all matrix entries
        if not smart_merge:
            # Full reset - delete existing matrix entries for this organization using ORM
            RoleProcessMatrix.query.filter_by(organization_id=org_id).delete()
            current_app.logger.info(f"[MATRIX INIT] Full reset - deleted existing matrix for org {org_id}")
        else:
            current_app.logger.info(f"[MATRIX INIT] Smart merge - preserving matrix for unchanged roles")

        # Get all process IDs using ORM
        all_processes = IsoProcesses.query.order_by(IsoProcesses.id).all()
        all_process_ids = [p.id for p in all_processes]

        if len(all_process_ids) != 30:
            current_app.logger.warning(f"[MATRIX INIT] Expected 30 processes, found {len(all_process_ids)}")

        entries_created = 0
        roles_skipped = 0

        for role in roles:
            role_id = role.get('id')
            role_name = role.get('orgRoleName')
            standard_cluster_id = role.get('standardRoleId')
            identification_method = role.get('identificationMethod', 'STANDARD')

            if not role_id:
                current_app.logger.warning(f"[MATRIX INIT] Skipping role without ID: {role_name}")
                continue

            # SMART MERGE: Skip roles that already have matrix data (unchanged roles)
            if smart_merge:
                existing_matrix_count = RoleProcessMatrix.query.filter_by(
                    organization_id=org_id,
                    role_cluster_id=role_id
                ).count()

                if existing_matrix_count > 0:
                    roles_skipped += 1
                    current_app.logger.info(
                        f"[MATRIX INIT] Skipping role '{role_name}' (ID: {role_id}) - "
                        f"matrix already exists ({existing_matrix_count} entries)"
                    )
                    continue

            if identification_method == 'STANDARD' and standard_cluster_id:
                # Find reference role in organization 1 (template org) with same cluster ID
                # NOTE: Org 1 is the template organization with all 14 standard roles and baseline matrix
                reference_role = OrganizationRoles.query.filter_by(
                    organization_id=1,
                    standard_role_cluster_id=standard_cluster_id
                ).first()

                if reference_role:
                    # Get reference matrix entries using ORM
                    reference_entries = RoleProcessMatrix.query.filter_by(
                        organization_id=1,
                        role_cluster_id=reference_role.id
                    ).all()

                    reference_values = {entry.iso_process_id: entry.role_process_value for entry in reference_entries}
                else:
                    current_app.logger.warning(
                        f"[MATRIX INIT] No reference role found for cluster {standard_cluster_id}, using zeros"
                    )
                    reference_values = {pid: 0 for pid in all_process_ids}

                # Insert matrix entries for this role using ORM
                for process_id in all_process_ids:
                    value = reference_values.get(process_id, 0)
                    new_entry = RoleProcessMatrix(
                        organization_id=org_id,
                        role_cluster_id=role_id,
                        iso_process_id=process_id,
                        role_process_value=value
                    )
                    db.session.add(new_entry)
                    entries_created += 1

                current_app.logger.info(
                    f"[MATRIX INIT] Copied {len(reference_values)} values for STANDARD role "
                    f"'{role_name}' (cluster {standard_cluster_id})"
                )

            elif identification_method == 'CUSTOM':
                # Use AI to generate intelligent matrix values for custom roles
                current_app.logger.info(f"[MATRIX INIT] Generating AI-powered matrix for CUSTOM role '{role_name}'")

                try:
                    # Prepare process list for AI
                    processes_for_ai = [{'id': p.id, 'name': p.name, 'description': p.description or ''} for p in all_processes]

                    # Get role description from the role object
                    role_description = role.get('standard_role_description', '') or role.get('description', '')

                    # Get existing matrix context (to make AI-generation context-aware)
                    existing_matrix_entries = RoleProcessMatrix.query.filter_by(organization_id=org_id).all()
                    existing_matrix = {}
                    for entry in existing_matrix_entries:
                        if entry.iso_process_id not in existing_matrix:
                            existing_matrix[entry.iso_process_id] = {}
                        existing_matrix[entry.iso_process_id][entry.role_cluster_id] = entry.role_process_value

                    # Get existing roles for context
                    existing_roles_objs = OrganizationRoles.query.filter_by(organization_id=org_id).all()
                    existing_roles = []
                    for r in existing_roles_objs:
                        existing_roles.append({
                            'id': r.id,
                            'orgRoleName': r.role_name,
                            'standardRoleName': r.standard_cluster.role_cluster_name if r.standard_cluster else None
                        })

                    # Call AI to generate matrix
                    ai_result = custom_role_matrix_generator.generate_matrix_for_custom_role(
                        role_name=role_name,
                        role_description=role_description,
                        processes=processes_for_ai,
                        existing_matrix=existing_matrix if existing_matrix else None,
                        existing_roles=existing_roles if existing_roles else None
                    )

                    if ai_result['success']:
                        ai_matrix = ai_result['matrix']
                        current_app.logger.info(f"[MATRIX INIT] AI generated matrix for '{role_name}': {ai_result.get('reasoning', '')}")

                        # Insert AI-generated values
                        for process_id in all_process_ids:
                            value = ai_matrix.get(process_id, 0)
                            new_entry = RoleProcessMatrix(
                                organization_id=org_id,
                                role_cluster_id=role_id,
                                iso_process_id=process_id,
                                role_process_value=value
                            )
                            db.session.add(new_entry)
                            entries_created += 1

                        current_app.logger.info(f"[MATRIX INIT] AI-generated {len(all_process_ids)} values for CUSTOM role '{role_name}'")
                    else:
                        # Fallback to zeros if AI fails
                        current_app.logger.warning(f"[MATRIX INIT] AI generation failed for '{role_name}', using zeros: {ai_result.get('error', 'Unknown error')}")
                        for process_id in all_process_ids:
                            new_entry = RoleProcessMatrix(
                                organization_id=org_id,
                                role_cluster_id=role_id,
                                iso_process_id=process_id,
                                role_process_value=0
                            )
                            db.session.add(new_entry)
                            entries_created += 1

                except Exception as ai_error:
                    # Fallback to zeros if AI generation fails
                    import traceback as tb
                    current_app.logger.error(f"[MATRIX INIT] AI generation error for '{role_name}': {str(ai_error)}")
                    current_app.logger.error(tb.format_exc())
                    current_app.logger.info(f"[MATRIX INIT] Falling back to zeros for CUSTOM role '{role_name}'")

                    for process_id in all_process_ids:
                        new_entry = RoleProcessMatrix(
                            organization_id=org_id,
                            role_cluster_id=role_id,
                            iso_process_id=process_id,
                            role_process_value=0
                        )
                        db.session.add(new_entry)
                        entries_created += 1
            else:
                current_app.logger.warning(
                    f"[MATRIX INIT] Unknown identification method '{identification_method}' for role '{role_name}'"
                )

        db.session.commit()

        # CRITICAL: Calculate role-competency matrix from role-process × process-competency
        # This is required for Phase 2 competency assessment to work!
        try:
            from sqlalchemy import text
            db.session.execute(
                text('CALL update_role_competency_matrix(:org_id);'),
                {'org_id': org_id}
            )
            db.session.commit()
            current_app.logger.info(f"[MATRIX INIT] Calculated role-competency matrix for org {org_id}")
        except Exception as calc_error:
            current_app.logger.error(f"[MATRIX INIT] Failed to calculate role-competency matrix: {calc_error}")
            # Don't fail the whole operation, but log the error
            import traceback
            current_app.logger.error(traceback.format_exc())

        # Build response message
        if smart_merge:
            message = f'Smart merge: initialized matrix for {len(roles) - roles_skipped} new roles, preserved {roles_skipped} unchanged roles'
        else:
            message = f'Initialized role-process matrix for {len(roles)} roles'

        return jsonify({
            'success': True,
            'message': message,
            'entries_created': entries_created,
            'roles_processed': len(roles),
            'roles_skipped': roles_skipped,
            'smart_merge': smart_merge,
            'processes_per_role': len(all_process_ids)
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"[MATRIX INIT ERROR] {str(e)}")
        import traceback
        current_app.logger.error(traceback.format_exc())
        return jsonify({'error': f'Failed to initialize matrix: {str(e)}'}), 500


@main_bp.route('/findProcesses', methods=['POST'])
def find_processes():
    """
    Map user tasks to ISO/IEC 15288 SE processes using AI
    Used in Phase 1 task-based role identification pathway
    """
    try:
        data = request.get_json()

        if not data:
            return jsonify({"error": "No input provided"}), 400

        # Extract required fields
        username = data.get('username')
        organization_id = data.get('organizationId')
        tasks = data.get('tasks', {})

        if not username or not organization_id:
            return jsonify({"error": "Username or Organization ID missing"}), 400

        # Extract task categories with defaults
        tasks_responsibilities = {
            "responsible_for": tasks.get("responsible_for", []),
            "supporting": tasks.get("supporting", []),
            "designing": tasks.get("designing", [])
        }

        print(f"[findProcesses] Processing tasks for user: {username}, org: {organization_id}")
        print(f"[findProcesses] Tasks: {tasks_responsibilities}")

        # Try to use LLM pipeline if available
        llm_success = False
        try:
            from app.services.llm_pipeline import llm_process_identification_pipeline
            pipeline = llm_process_identification_pipeline.create_pipeline()

            result = pipeline(tasks_responsibilities)

            print(f"[findProcesses] DEBUG: Pipeline returned result: {result}")
            print(f"[findProcesses] DEBUG: Result type: {type(result)}")
            print(f"[findProcesses] DEBUG: Result status: {result.get('status') if isinstance(result, dict) else 'NOT A DICT'}")

            # Handle invalid tasks case
            if result.get("status") == "invalid_tasks":
                return jsonify({
                    "status": "invalid_tasks",
                    "message": result.get("message", "Tasks are invalid or empty")
                }), 400

            # Handle success case
            elif result.get("status") == "success":
                print("[findProcesses] ============ LLM SUCCESS BLOCK ENTERED ============")
                # Extract process involvement from LLM result
                llm_result = result.get("result")
                processes_list = llm_result.processes if hasattr(llm_result, 'processes') else []

                # Format response for frontend
                processes = [
                    {
                        "process_name": process.process_name,
                        "involvement": process.involvement
                    }
                    for process in processes_list
                ]

                print(f"[findProcesses] Formatted {len(processes)} processes for response")
                llm_success = True

                # Extract LLM role suggestion if available
                llm_role_suggestion = result.get("llm_role_suggestion", None)

                # DERIK'S APPROACH: Store in UnknownRoleProcessMatrix for competency calculation
                try:
                    from models import UnknownRoleProcessMatrix, IsoProcesses, db
                    from sqlalchemy import text

                    print(f"[findProcesses] Starting DB storage for username: {username}, org: {organization_id}")

                    # Fetch ALL ISO Processes from database
                    iso_processes = IsoProcesses.query.with_entities(IsoProcesses.id, IsoProcesses.name).all()
                    print(f"[findProcesses] Fetched {len(iso_processes)} ISO processes from DB")
                    iso_process_map = {
                        process.name.strip().lower(): process.id for process in iso_processes
                    }

                    # Create process involvement map from LLM result
                    # Strip " process" suffix from LLM output to match database format
                    llm_process_map = {}
                    for process in processes:
                        name = process.get('process_name', '').strip().lower()
                        # Remove " process" suffix if present
                        if name.endswith(' process'):
                            name = name[:-8]  # Remove last 8 characters (" process")
                        llm_process_map[name] = process.get('involvement', 'Not performing')

                    # Delete existing entries for this user to avoid duplicates
                    UnknownRoleProcessMatrix.query.filter_by(
                        user_name=username,
                        organization_id=organization_id
                    ).delete()

                    # Prepare rows to insert (one row per ISO process)
                    rows_to_insert = []
                    for process in iso_processes:
                        process_name = process.name.strip().lower()
                        iso_process_id = process.id

                        # Determine involvement from LLM output
                        involvement = llm_process_map.get(process_name, "Not performing")

                        # Map involvement to numeric value
                        # CRITICAL: These values multiply with process_competency_value (1,2,3)
                        # Valid results must match stored procedure CASE: {0,1,2,3,4,6}
                        # Designing(3) * Apply(3) = 9 is not handled, but Designing(3) * Understand(2) = 6 is valid
                        involvement_values = {
                            "Responsible": 2,
                            "Supporting": 1,
                            "Designing": 4,  # FIXED: Must be 4 to match database CHECK constraint
                            "Not performing": 0
                        }
                        role_process_value = involvement_values.get(involvement, 0)

                        # Add row to insert
                        rows_to_insert.append(UnknownRoleProcessMatrix(
                            user_name=username,
                            iso_process_id=iso_process_id,
                            role_process_value=role_process_value,
                            organization_id=organization_id
                        ))

                    # Bulk insert
                    if rows_to_insert:
                        print(f"[findProcesses] Inserting {len(rows_to_insert)} process rows")
                        db.session.bulk_save_objects(rows_to_insert)
                        db.session.commit()
                        print(f"[findProcesses] Successfully inserted process data")
                    else:
                        print(f"[findProcesses] WARNING: No rows to insert!")

                    # Call stored procedure to calculate competency requirements from process involvement
                    try:
                        print(f"[findProcesses] Calling stored procedure update_unknown_role_competency_values")
                        db.session.execute(
                            text("CALL update_unknown_role_competency_values(:username, :organization_id);"),
                            {"username": username, "organization_id": organization_id}
                        )
                        db.session.commit()
                        print(f"[findProcesses] Stored procedure completed successfully")
                    except Exception as proc_error:
                        print(f"[findProcesses] ERROR in stored procedure: {str(proc_error)}")
                        import traceback
                        print(traceback.format_exc())
                        db.session.rollback()
                        # Continue anyway - competency calculation can be done later

                except Exception as db_error:
                    print(f"[findProcesses] ERROR in DB operations: {str(db_error)}")
                    import traceback
                    print(traceback.format_exc())
                    db.session.rollback()
                    # Continue anyway - return processes to frontend

                response_data = {
                    "status": "success",
                    "processes": processes
                }

                # Add LLM role suggestion if available
                if llm_role_suggestion:
                    response_data["llm_role_suggestion"] = llm_role_suggestion

                print("=" * 80)
                print("[SUCCESS] LLM pipeline used successfully for process identification")
                print(f"[SUCCESS] Identified {len(processes)} processes using AI-based analysis")
                print("=" * 80)
                return jsonify(response_data), 200

        except ImportError as import_err:
            print("=" * 80)
            print(f"[ERROR] LLM pipeline import failed: {str(import_err)}")
            print("[FALLBACK] Using keyword matching instead")
            print("=" * 80)
        except Exception as llm_err:
            print("=" * 80)
            print(f"[ERROR] LLM pipeline execution failed: {str(llm_err)}")
            print("[FALLBACK] Using keyword matching instead")
            import traceback
            print(traceback.format_exc())
            print("=" * 80)

        # Fallback: Simple keyword-based process identification
        if not llm_success:
            print("=" * 80)
            print("[WARNING] FALLBACK MODE ACTIVE: Using keyword-based process identification")
            print("[INFO] This is a simplified fallback mechanism with limited accuracy")
            print("[INFO] For better results, ensure LLM pipeline is properly configured")
            print("=" * 80)
            processes = []
            combined_tasks = ' '.join(
                tasks_responsibilities.get("responsible_for", []) +
                tasks_responsibilities.get("supporting", []) +
                tasks_responsibilities.get("designing", [])
            ).lower()

            # Map keywords to ISO 15288 processes
            process_keywords = {
                'Business or Mission Analysis': ['business', 'mission', 'strategy', 'goals', 'objectives'],
                'Stakeholder Needs and Requirements Definition': ['stakeholder', 'needs', 'requirements', 'gather', 'elicit'],
                'System Requirements Definition': ['system requirements', 'specification', 'define requirements'],
                'System Architecture Definition': ['architecture', 'design', 'structure', 'components', 'interfaces'],
                'Implementation': ['implement', 'code', 'develop', 'build', 'program'],
                'Integration': ['integrate', 'combine', 'merge', 'connect', 'assemble'],
                'Verification': ['verify', 'test', 'check', 'validate', 'inspect'],
                'Transition': ['deploy', 'release', 'transition', 'deliver', 'install'],
                'Validation': ['validate', 'acceptance', 'user testing', 'customer'],
                'Operation': ['operate', 'run', 'maintain', 'monitor', 'support'],
                'Maintenance': ['maintain', 'fix', 'update', 'patch', 'service'],
                'Disposal': ['dispose', 'retire', 'decommission', 'remove', 'shutdown']
            }

            for process_name, keywords in process_keywords.items():
                if any(keyword in combined_tasks for keyword in keywords):
                    # Determine involvement based on task category
                    if any(keyword in ' '.join(tasks_responsibilities.get("designing", [])).lower() for keyword in keywords):
                        involvement = "Designing"
                    elif any(keyword in ' '.join(tasks_responsibilities.get("responsible_for", [])).lower() for keyword in keywords):
                        involvement = "Responsible"
                    else:
                        involvement = "Supporting"

                    processes.append({
                        "process_name": process_name,
                        "involvement": involvement
                    })

            # Default processes if none found
            if not processes:
                processes = [
                    {"process_name": "System Architecture Definition", "involvement": "Responsible"},
                    {"process_name": "System Requirements Definition", "involvement": "Responsible"},
                    {"process_name": "Implementation", "involvement": "Responsible"}
                ]

            print(f"[findProcesses] Fallback identified {len(processes)} processes")

            return jsonify({
                "status": "success",
                "processes": processes,
                "fallback": True
            }), 200

    except Exception as e:
        print(f"[findProcesses] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@main_bp.route('/phase1/roles/suggest-from-processes', methods=['POST'])
def suggest_role_from_processes():
    """
    DERIK'S SIMPLE APPROACH: Pure competency-based distance matching
    - Uses Euclidean distance between user and role competency vectors
    - Returns role(s) with minimum distance
    - Confidence based on distance separation
    """
    try:
        from models import RoleCluster, UnknownRoleCompetencyMatrix
        from app.most_similar_role import find_most_similar_role_cluster

        data = request.get_json()

        if not data:
            return jsonify({'error': 'No input provided'}), 400

        username = data.get('username')
        organization_id = data.get('organizationId', 11)

        if not username:
            return jsonify({'error': 'Username required'}), 400

        print(f"[suggest-role-simple] Analyzing user: {username} (org: {organization_id})")

        # ====================
        # STEP 1: Get user's competency requirements
        # ====================
        competencies = UnknownRoleCompetencyMatrix.query.filter_by(
            user_name=username,
            organization_id=organization_id
        ).all()

        if not competencies:
            print(f"[suggest-role-simple] No competency data for user: {username}")
            return jsonify({
                'error': 'No competency data available. Please complete task analysis first.',
                'debug': {
                    'username': username,
                    'organization_id': organization_id,
                    'hint': 'Call /findProcesses endpoint first'
                }
            }), 400

        user_scores = [
            {'competency_id': c.competency_id, 'score': c.role_competency_value}
            for c in competencies
        ]

        print(f"[suggest-role-simple] User has {len(user_scores)} competency requirements")

        # ====================
        # STEP 2: Find most similar role using Euclidean distance
        # ====================
        result = find_most_similar_role_cluster(organization_id, user_scores)

        if not result or not result.get('role_ids'):
            print("[suggest-role-simple] No similar roles found")
            return jsonify({
                'error': 'No matching roles found',
                'debug': result
            }), 404

        # ====================
        # STEP 3: Calculate confidence based on distance separation
        # ====================
        best_role_id = result['role_ids'][0]
        distances = result['distances']['euclidean']
        metric_agreement = result.get('metric_agreement', 0)

        # Get all distances sorted
        sorted_distances = sorted(distances.items(), key=lambda x: x[1])

        if len(sorted_distances) >= 2:
            best_distance = sorted_distances[0][1]
            second_best_distance = sorted_distances[1][1]

            # Calculate separation (how much better is #1 vs #2)
            if second_best_distance > 0:
                separation = (second_best_distance - best_distance) / second_best_distance
            else:
                separation = 1.0

            # Confidence based on:
            # 1. All 3 distance metrics agree (metric_agreement = 3): +0.15
            # 2. Good separation from second best: up to +0.30
            base_confidence = 0.55
            agreement_bonus = 0.15 if metric_agreement == 3 else (0.10 if metric_agreement == 2 else 0.05)
            separation_bonus = separation * 0.30

            confidence = min(base_confidence + agreement_bonus + separation_bonus, 0.95)
        else:
            # Only one role found
            confidence = 0.80 if metric_agreement == 3 else 0.70

        print(f"[suggest-role-simple] Best role ID: {best_role_id}")
        print(f"[suggest-role-simple] Euclidean distance: {distances[best_role_id]:.4f}")
        print(f"[suggest-role-simple] Metric agreement: {metric_agreement}/3")
        print(f"[suggest-role-simple] Confidence: {confidence:.0%}")

        # ====================
        # STEP 4: Build response
        # ====================
        best_role = RoleCluster.query.get(best_role_id)

        if not best_role:
            return jsonify({'error': 'Role not found in database'}), 500

        # Get alternative roles (next 2 best matches)
        alternative_roles = []
        for role_id, distance in sorted_distances[1:3]:
            role = RoleCluster.query.get(role_id)
            if role:
                alt_confidence = confidence * 0.75  # Lower confidence for alternatives
                alt_role_dict = role.to_dict()
                alt_role_dict['confidence'] = round(alt_confidence, 2)
                alt_role_dict['distance'] = round(distance, 4)
                alternative_roles.append(alt_role_dict)

        response_data = {
            'suggestedRole': best_role.to_dict(),
            'confidence': round(confidence, 2),
            'alternativeRoles': alternative_roles,
            'debug': {
                'method': 'COMPETENCY_DISTANCE (Euclidean)',
                'euclidean_distance': round(distances[best_role_id], 4),
                'metric_agreement': f"{metric_agreement}/3",
                'all_distances': {
                    RoleCluster.query.get(rid).role_cluster_name: round(dist, 4)
                    for rid, dist in sorted_distances[:5]
                    if RoleCluster.query.get(rid)
                }
            }
        }

        print(f"[suggest-role-simple] RESULT: {best_role.role_cluster_name} ({confidence:.0%} confidence)")
        return jsonify(response_data), 200

    except Exception as e:
        print(f"[suggest-role-simple] ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Internal server error',
            'details': str(e)
        }), 500


@main_bp.route('/phase1/target-group/<int:org_id>', methods=['GET'])
def get_target_group(org_id):
    """Get target group size for an organization"""
    try:
        from models import PhaseQuestionnaireResponse, Organization

        # Verify organization exists
        org = Organization.query.get(org_id)
        if not org:
            return jsonify({'error': 'Organization not found'}), 404

        # Get latest target group data
        target_group = PhaseQuestionnaireResponse.query.filter_by(
            organization_id=org_id,
            questionnaire_type='target_group',
            phase=1
        ).order_by(PhaseQuestionnaireResponse.completed_at.desc()).first()

        if not target_group:
            return jsonify({
                'success': True,
                'data': None
            }), 200

        # Get the response data
        response_data = target_group.get_responses()

        return jsonify({
            'success': True,
            'data': response_data,
            'completed_at': target_group.completed_at.isoformat() if target_group.completed_at else None
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting target group: {str(e)}")
        return jsonify({'error': 'Failed to get target group'}), 500


@main_bp.route('/phase1/target-group/save', methods=['POST'])
def save_target_group():
    """Save target group size information"""
    try:
        from models import PhaseQuestionnaireResponse
        from flask_jwt_extended import verify_jwt_in_request

        data = request.get_json()

        org_id = data.get('org_id')
        size_data = data.get('sizeData', {})

        if not org_id:
            return jsonify({'error': 'org_id is required'}), 400

        # Get user ID from JWT if available
        user_id = 1  # Default fallback
        try:
            verify_jwt_in_request(optional=True)
            jwt_user_id = get_jwt_identity()
            if jwt_user_id:
                user_id = int(jwt_user_id) if isinstance(jwt_user_id, str) else jwt_user_id
        except Exception:
            pass  # Use default user_id

        # Create new target group data
        target_group = PhaseQuestionnaireResponse(
            organization_id=org_id,
            user_id=user_id,
            questionnaire_type='target_group',
            phase=1
        )
        target_group.set_responses(size_data)

        db.session.add(target_group)
        db.session.commit()

        return jsonify({
            'success': True,
            'id': target_group.id,
            'message': 'Target group saved successfully'
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error saving target group: {str(e)}")
        return jsonify({'error': 'Failed to save target group'}), 500


@main_bp.route('/phase1/strategies/definitions', methods=['GET'])
def get_strategy_definitions():
    """Get all 7 SE training strategy definitions"""
    try:
        from app.strategy_selection_engine import SE_TRAINING_STRATEGIES

        return jsonify({
            'success': True,
            'strategies': SE_TRAINING_STRATEGIES
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting strategy definitions: {str(e)}")
        return jsonify({'error': 'Failed to get strategy definitions'}), 500


@main_bp.route('/phase1/strategies/calculate', methods=['POST'])
def calculate_strategies():
    """Calculate recommended strategies based on maturity and target group"""
    try:
        from app.strategy_selection_engine import StrategySelectionEngine

        data = request.get_json()
        maturity_data = data.get('maturityData', {})
        target_group_data = data.get('targetGroupData', {})

        if not maturity_data or not target_group_data:
            return jsonify({'error': 'maturityData and targetGroupData are required'}), 400

        # Run strategy selection engine
        engine = StrategySelectionEngine(maturity_data, target_group_data)
        results = engine.select_strategies()

        return jsonify({
            'success': True,
            'strategies': results['strategies'],
            'decisionPath': results['decisionPath'],
            'reasoning': results['reasoning'],
            'requiresUserChoice': results['requiresUserChoice']
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error calculating strategies: {str(e)}")
        return jsonify({'error': f'Failed to calculate strategies: {str(e)}'}), 500


@main_bp.route('/phase1/strategies/<int:org_id>/latest', methods=['GET'])
def get_latest_strategies(org_id):
    """Get latest strategy selection for an organization"""
    try:
        from models import PhaseQuestionnaireResponse, Organization

        # Verify organization exists
        org = Organization.query.get(org_id)
        if not org:
            return jsonify({'error': 'Organization not found'}), 404

        # Get latest strategy selection
        strategies = PhaseQuestionnaireResponse.query.filter_by(
            organization_id=org_id,
            questionnaire_type='strategies',
            phase=1
        ).order_by(PhaseQuestionnaireResponse.completed_at.desc()).first()

        if not strategies:
            return jsonify({
                'success': True,
                'data': None,
                'count': 0
            }), 200

        # Parse the response
        response_data = strategies.get_responses()
        strategies_list = response_data.get('strategies', []) if isinstance(response_data, dict) else []

        return jsonify({
            'success': True,
            'data': strategies_list,
            'count': len(strategies_list),
            'userPreference': response_data.get('userPreference') if isinstance(response_data, dict) else None,
            'decisionPath': response_data.get('decisionPath') if isinstance(response_data, dict) else None,
            'reasoning': response_data.get('reasoning') if isinstance(response_data, dict) else None,
            'completed_at': strategies.completed_at.isoformat() if strategies.completed_at else None
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting strategies: {str(e)}")
        return jsonify({'error': 'Failed to get strategies'}), 500


@main_bp.route('/phase1/strategies/save', methods=['POST'])
def save_strategies():
    """Save selected strategies"""
    try:
        from models import PhaseQuestionnaireResponse, LearningStrategy
        from flask_jwt_extended import verify_jwt_in_request

        data = request.get_json()

        org_id = data.get('orgId')
        strategies = data.get('strategies', [])
        decision_path = data.get('decisionPath', [])

        if not org_id:
            return jsonify({'error': 'orgId is required'}), 400

        # Get user ID from JWT if available
        user_id = 1  # Default fallback
        try:
            verify_jwt_in_request(optional=True)
            jwt_user_id = get_jwt_identity()
            if jwt_user_id:
                user_id = int(jwt_user_id) if isinstance(jwt_user_id, str) else jwt_user_id
        except Exception:
            pass  # Use default user_id

        # Create new strategy selection in PhaseQuestionnaireResponse
        strategy_data = PhaseQuestionnaireResponse(
            organization_id=org_id,
            user_id=user_id,
            questionnaire_type='strategies',
            phase=1
        )
        strategy_data.set_responses({
            'strategies': strategies,
            'decision_path': decision_path
        })

        db.session.add(strategy_data)

        # CRITICAL FIX: Sync strategies to learning_strategy table for Phase 2
        # Clear existing selected strategies for this organization
        LearningStrategy.query.filter_by(organization_id=org_id).update({'selected': False})

        # Map of strategy keys to display names
        strategy_names = {
            'foundation_workshop': 'Foundation Workshop',
            'advanced_training': 'Advanced Training',
            'needs_based_project': 'Needs-based Project-oriented Training',
            'continuous_support': 'Continuous Support',
            'se_for_managers': 'SE for Managers',
            'common_understanding': 'Common Basic Understanding'
        }
        # Helper: Map strategy names to strategy_template IDs for LO generation
        def find_strategy_template_id(display_name):
            name_lower = display_name.lower().strip()
            template_mappings = {
                'common basic understanding': 1, 'common understanding': 1,
                'se for managers': 2,
                'orientation in pilot project': 3, 'pilot project': 3, 'foundation workshop': 3,
                'needs-based, project-oriented training': 4, 'needs-based project-oriented training': 4, 'advanced training': 4,
                'continuous support': 5,
                'train the trainer': 6, 'train the se-trainer': 6,
                'certification': 7
            }
            if name_lower in template_mappings:
                return template_mappings[name_lower]
            for pattern, tid in template_mappings.items():
                if pattern in name_lower or name_lower in pattern:
                    return tid
            return None


        # Priority mapping from Phase 1 to numeric priority
        priority_map = {
            'PRIMARY': 1,
            'SECONDARY': 2,
            'SUPPLEMENTARY': 3
        }

        # Add or update selected strategies
        for strategy_item in strategies:
            strategy_key = strategy_item.get('strategy')
            strategy_display_name = strategy_item.get('strategyName') or strategy_names.get(strategy_key, strategy_key)
            priority_str = strategy_item.get('priority', 'SECONDARY')
            priority_num = priority_map.get(priority_str, 2)
            reason = strategy_item.get('reason', '')

            # Get strategy_template_id for LO generation
            template_id = find_strategy_template_id(strategy_display_name)
            # Try to find existing strategy
            existing = LearningStrategy.query.filter_by(
                organization_id=org_id,
                strategy_name=strategy_display_name
            ).first()

            if existing:
                # Update existing
                existing.selected = True
                existing.priority = priority_num
                existing.strategy_description = reason
                existing.strategy_template_id = template_id
            else:
                # Create new
                new_strategy = LearningStrategy(
                    organization_id=org_id,
                    strategy_name=strategy_display_name,
                    strategy_description=reason,
                    selected=True,
                    priority=priority_num,
                    strategy_template_id=template_id
                )
                db.session.add(new_strategy)

        db.session.commit()

        current_app.logger.info(f"[OK] Saved {len(strategies)} strategies for org {org_id} to both tables")

        return jsonify({
            'success': True,
            'id': strategy_data.id,
            'message': 'Strategies saved successfully',
            'strategies': strategies,
            'count': len(strategies)
        }), 201

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"[ERROR] Failed to save strategies: {str(e)}")
        return jsonify({'error': 'Failed to save strategies'}), 500


# =============================================================================
# AI ROLE MAPPING ENDPOINTS (Phase 1 Task 2 Enhancement)
# Maps organization-specific roles to SE role clusters using AI
# =============================================================================

@main_bp.route('/phase1/role-clusters', methods=['GET'])
def get_role_clusters_for_mapping():
    """Get all 14 SE role clusters for AI mapping"""
    try:
        clusters = role_mapping_service.get_all_role_clusters()
        return jsonify({
            'success': True,
            'role_clusters': clusters,
            'total': len(clusters)
        })
    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to get role clusters: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/extract-roles-from-document', methods=['POST'])
def extract_roles_from_document():
    """
    Extract role information from uploaded documents (PDF, DOC, DOCX, TXT)
    Uses OpenAI to parse document text and extract structured role data
    """
    try:
        # Check if file is present
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'No file uploaded'}), 400

        file = request.files['file']
        organization_id = request.form.get('organization_id')

        if not file or file.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'}), 400

        if not organization_id:
            return jsonify({'success': False, 'error': 'organization_id is required'}), 400

        # Get file extension
        filename = file.filename.lower()

        # Extract text based on file type
        extracted_text = None

        if filename.endswith('.txt'):
            extracted_text = file.read().decode('utf-8', errors='ignore')

        elif filename.endswith('.pdf'):
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(file)
                text_parts = []
                for page in pdf_reader.pages:
                    text_parts.append(page.extract_text())
                extracted_text = '\n'.join(text_parts)
            except Exception as e:
                current_app.logger.error(f"[ERROR] PDF extraction failed: {str(e)}")
                return jsonify({'success': False, 'error': f'Failed to extract text from PDF: {str(e)}'}), 500

        elif filename.endswith('.docx'):
            try:
                import docx
                doc = docx.Document(file)
                text_parts = [para.text for para in doc.paragraphs]
                extracted_text = '\n'.join(text_parts)
            except Exception as e:
                current_app.logger.error(f"[ERROR] DOCX extraction failed: {str(e)}")
                return jsonify({'success': False, 'error': f'Failed to extract text from DOCX: {str(e)}'}), 500

        else:
            return jsonify({'success': False, 'error': 'Unsupported file format. Please upload PDF, DOCX, or TXT files.'}), 400

        if not extracted_text or len(extracted_text.strip()) < 50:
            return jsonify({'success': False, 'error': 'Document appears to be empty or too short'}), 400

        # Use OpenAI to extract role information
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

        prompt = f"""You are an expert in analyzing organizational role descriptions.
Extract all roles mentioned in the following document and structure them as a JSON array.

For each role, extract:
- title: The job title or role name
- description: A brief description of the role
- responsibilities: An array of key responsibilities (at least 2-3 if mentioned)
- skills: An array of required skills/technologies (if mentioned)

If a role doesn't have explicit responsibilities or skills listed, infer them from the description.

Document text:
{extracted_text[:8000]}

Return ONLY a valid JSON array of roles, nothing else. Example format:
[
  {{
    "title": "Software Engineer",
    "description": "Develops and maintains software applications",
    "responsibilities": ["Write code", "Debug issues", "Review code"],
    "skills": ["Python", "JavaScript", "Git"]
  }}
]
"""

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that extracts structured role information from documents. Always respond with valid JSON only."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )

            ai_response = response.choices[0].message.content.strip()

            # Remove markdown code blocks if present
            if ai_response.startswith('```'):
                ai_response = ai_response.split('```')[1]
                if ai_response.startswith('json'):
                    ai_response = ai_response[4:]
                ai_response = ai_response.strip()

            # Parse JSON response
            roles = json.loads(ai_response)

            if not isinstance(roles, list):
                raise ValueError("Expected an array of roles")

            current_app.logger.info(f"[OK] Extracted {len(roles)} roles from document")

            return jsonify({
                'success': True,
                'roles': roles,
                'total': len(roles)
            })

        except json.JSONDecodeError as e:
            current_app.logger.error(f"[ERROR] Failed to parse AI response: {str(e)}")
            current_app.logger.error(f"[ERROR] AI response was: {ai_response}")
            return jsonify({'success': False, 'error': 'Failed to parse role information from document'}), 500

    except Exception as e:
        current_app.logger.error(f"[ERROR] Document extraction failed: {str(e)}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/map-roles', methods=['POST'])
def map_organization_roles():
    """
    Map organization roles to SE-QPT clusters using AI

    Request body:
    {
        "organization_id": 123,
        "roles": [
            {
                "title": "Senior Software Developer",
                "description": "Develops embedded software...",
                "responsibilities": ["Design software modules", ...],
                "skills": ["C++", "Python", ...]
            }
        ]
    }
    """
    try:
        data = request.get_json()
        organization_id = data.get('organization_id')
        roles = data.get('roles', [])

        if not organization_id:
            return jsonify({'success': False, 'error': 'organization_id is required'}), 400

        if not roles:
            return jsonify({'success': False, 'error': 'roles array is required'}), 400

        # Perform AI mapping
        result = role_mapping_service.map_multiple_roles(roles)

        if 'error' in result:
            return jsonify({'success': False, 'error': result['error']}), 500

        return jsonify({
            'success': True,
            'data': result
        })

    except Exception as e:
        current_app.logger.error(f"[ERROR] Role mapping failed: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/role-mappings/<int:org_id>', methods=['GET'])
def get_role_mappings(org_id):
    """Get all role mappings for an organization"""
    try:
        mappings = OrganizationRoleMapping.query.filter_by(
            organization_id=org_id
        ).order_by(OrganizationRoleMapping.org_role_title).all()

        result = []
        for m in mappings:
            result.append({
                'id': m.id,
                'org_role_title': m.org_role_title,
                'org_role_description': m.org_role_description,
                'mapped_cluster': {
                    'id': m.mapped_cluster_id,
                    'name': m.role_cluster.role_cluster_name if m.role_cluster else None,
                    'description': m.role_cluster.role_cluster_description if m.role_cluster else None
                },
                'confidence_score': float(m.confidence_score) if m.confidence_score else None,
                'reasoning': m.mapping_reasoning,
                'matched_responsibilities': json.loads(m.matched_responsibilities) if m.matched_responsibilities else [],
                'user_confirmed': m.user_confirmed,
                'created_at': m.created_at.isoformat() if m.created_at else None
            })

        return jsonify({
            'success': True,
            'mappings': result,
            'total': len(result)
        })

    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to get role mappings: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/role-mappings/<int:mapping_id>', methods=['PUT'])
def update_role_mapping(mapping_id):
    """
    Update a role mapping (confirm, reject, or modify)

    Request body:
    {
        "user_confirmed": true,
        "confirmed_by": 456
    }
    """
    try:
        data = request.get_json()
        mapping = OrganizationRoleMapping.query.get(mapping_id)

        if not mapping:
            return jsonify({'success': False, 'error': 'Mapping not found'}), 404

        if 'user_confirmed' in data:
            mapping.user_confirmed = data['user_confirmed']
            mapping.confirmed_by = data.get('confirmed_by')
            if data['user_confirmed']:
                from datetime import datetime
                mapping.confirmed_at = datetime.utcnow()

        db.session.commit()

        return jsonify({
            'success': True,
            'message': 'Mapping updated successfully'
        })

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"[ERROR] Failed to update role mapping: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/role-mappings/<int:mapping_id>', methods=['DELETE'])
def delete_role_mapping(mapping_id):
    """Delete a role mapping"""
    try:
        mapping = OrganizationRoleMapping.query.get(mapping_id)

        if not mapping:
            return jsonify({'success': False, 'error': 'Mapping not found'}), 404

        db.session.delete(mapping)
        db.session.commit()

        return jsonify({
            'success': True,
            'message': 'Mapping deleted successfully'
        })

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"[ERROR] Failed to delete role mapping: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase1/organization-structure/<int:org_id>', methods=['GET'])
def get_organization_structure_analysis(org_id):
    """
    Get organization structure analysis showing which role clusters are present.
    This is DESCRIPTIVE only - does NOT warn about "missing" clusters.
    """
    try:
        # Get all clusters
        all_clusters = role_mapping_service.get_all_role_clusters()

        # Get confirmed mappings for this organization
        mappings = OrganizationRoleMapping.query.filter_by(
            organization_id=org_id,
            user_confirmed=True
        ).all()

        # Get unique cluster IDs that are covered
        covered_cluster_ids = set(m.mapped_cluster_id for m in mappings)

        covered_clusters = [c for c in all_clusters if c['id'] in covered_cluster_ids]
        present_count = len(covered_clusters)

        # Get organization roles that map to each cluster
        cluster_roles = defaultdict(list)
        for m in mappings:
            cluster_roles[m.mapped_cluster_id].append({
                'title': m.org_role_title,
                'confidence': float(m.confidence_score) if m.confidence_score else None
            })

        # Build analysis (DESCRIPTIVE only, no gap warnings)
        analysis = {
            'organization_id': org_id,
            'total_possible_clusters': len(all_clusters),
            'present_clusters_count': present_count,
            'present_clusters': [
                {
                    'id': c['id'],
                    'name': c['name'],
                    'description': c['description'],
                    'org_roles': cluster_roles.get(c['id'], [])
                }
                for c in covered_clusters
            ],
            'summary': f"Organization has roles in {present_count} of {len(all_clusters)} SE role clusters"
        }

        return jsonify({
            'success': True,
            'analysis': analysis
        })

    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to get organization structure: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


# =============================================================================
# ADMIN MATRIX MANAGEMENT ENDPOINTS
# Based on Derik's implementation and MATRIX_CALCULATION_PATTERN.md
# =============================================================================

@main_bp.route('/roles', methods=['GET'])
@jwt_required()
def get_role_clusters():
    """
    Get organization-specific roles for competency assessment.

    Fixed: 2025-10-30 - Now returns user's organization roles instead of generic 14 clusters.
    This fixes:
    - "No competencies found" error in Phase 2 (role IDs now match role_competency_matrix)
    - Auto-selection bug when roles share same cluster (each org role now has unique ID)
    """
    print("[GET ROLES] Endpoint called")
    try:
        # Get authenticated user's organization_id
        print("[GET ROLES] Getting JWT identity...")
        user_id = int(get_jwt_identity())
        print(f"[GET ROLES] JWT user_id: {user_id}")

        user = User.query.get(user_id)
        print(f"[GET ROLES] Found user: {user.username if user else 'None'}")

        if not user:
            print("[GET ROLES ERROR] User not found")
            return jsonify({'error': 'User not found'}), 404

        organization_id = user.organization_id
        print(f"[GET ROLES] Organization ID: {organization_id}")

        if not organization_id:
            print("[GET ROLES ERROR] User has no organization")
            return jsonify({'error': 'User has no organization'}), 400

        # Return organization's actual roles (not generic clusters)
        roles = OrganizationRoles.query.filter_by(organization_id=organization_id).order_by(OrganizationRoles.id).all()
        print(f"[GET ROLES] Found {len(roles)} roles")

        # Use to_dict() for consistent output
        roles_list = [role.to_dict() for role in roles]

        current_app.logger.info(f"[GET ROLES] Returned {len(roles_list)} organization-specific roles for org {organization_id}")
        print(f"[GET ROLES] Returning {len(roles_list)} organization-specific roles for org {organization_id}")

        return jsonify(roles_list), 200

    except Exception as e:
        current_app.logger.error(f"[GET ROLES ERROR] {str(e)}")
        print(f"[GET ROLES ERROR] Exception: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': 'Failed to fetch roles', 'details': str(e)}), 500


@main_bp.route('/organization_roles/<int:org_id>', methods=['GET'])
def get_organization_roles(org_id):
    """
    Get roles for a specific organization from organization_roles table.

    Refactored: 2025-10-30 - Now uses ORM instead of raw SQL
    """
    try:
        # Verify organization exists
        org = Organization.query.get(org_id)
        if not org:
            return jsonify({'error': 'Organization not found'}), 404

        # Fetch roles using ORM (relationships handle the JOIN automatically)
        roles = OrganizationRoles.query.filter_by(organization_id=org_id).order_by(OrganizationRoles.id).all()

        # Use to_dict() for consistent output
        roles_list = [role.to_dict() for role in roles]

        current_app.logger.info(f"[GET ORG ROLES] Fetched {len(roles_list)} roles for organization {org_id}")
        return jsonify(roles_list), 200

    except Exception as e:
        current_app.logger.error(f"[GET ORG ROLES] Error: {str(e)}")
        return jsonify({'error': 'Failed to get organization roles'}), 500


@main_bp.route('/roles_and_processes', methods=['GET'])
def get_roles_and_processes():
    """Get all roles and processes for admin matrix editing"""
    try:
        roles = RoleCluster.query.all()
        processes = IsoProcesses.query.all()

        return jsonify({
            'roles': [r.to_dict() for r in roles],
            'processes': [p.to_dict() for p in processes]
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error fetching roles and processes: {str(e)}")
        return jsonify({'error': 'Failed to fetch roles and processes'}), 500


@main_bp.route('/role_process_matrix/<int:organization_id>/<int:role_id>', methods=['GET'])
def get_role_process_matrix(organization_id, role_id):
    """Get role-process matrix values for a specific role and organization"""
    try:
        matrix_entries = RoleProcessMatrix.query.filter_by(
            organization_id=organization_id,
            role_cluster_id=role_id
        ).all()

        return jsonify([entry.to_dict() for entry in matrix_entries]), 200

    except Exception as e:
        current_app.logger.error(f"Error fetching role-process matrix: {str(e)}")
        return jsonify({'error': 'Failed to fetch role-process matrix'}), 500


@main_bp.route('/role_process_matrix/bulk', methods=['PUT'])
def bulk_update_role_process_matrix():
    """
    Bulk update role-process matrix and recalculate role-competency matrix
    Based on Derik's implementation (routes.py:250)
    """
    try:
        data = request.get_json()
        organization_id = data.get('organization_id')
        role_cluster_id = data.get('role_cluster_id')
        matrix = data.get('matrix')  # Dict: {process_id: value}

        if not all([organization_id, role_cluster_id, matrix]):
            return jsonify({'error': 'Missing required fields'}), 400

        # Update or create matrix entries
        for process_id, value in matrix.items():
            process_id = int(process_id)

            # Find existing entry or create new one
            entry = RoleProcessMatrix.query.filter_by(
                organization_id=organization_id,
                role_cluster_id=role_cluster_id,
                iso_process_id=process_id
            ).first()

            if entry:
                entry.role_process_value = value
            else:
                entry = RoleProcessMatrix(
                    organization_id=organization_id,
                    role_cluster_id=role_cluster_id,
                    iso_process_id=process_id,
                    role_process_value=value
                )
                db.session.add(entry)

        db.session.commit()

        # Recalculate role-competency matrix for this organization
        # As per MATRIX_CALCULATION_PATTERN.md
        print(f"[ROLE-PROCESS MATRIX] Calling stored procedure to recalculate role-competency matrix for org {organization_id}")
        current_app.logger.info(f"[ROLE-PROCESS MATRIX] Calling stored procedure to recalculate role-competency matrix for org {organization_id}")
        db.session.execute(
            text('CALL update_role_competency_matrix(:org_id);'),
            {'org_id': organization_id}
        )
        db.session.commit()
        print(f"[ROLE-PROCESS MATRIX] Successfully recalculated role-competency matrix for org {organization_id}")
        current_app.logger.info(f"[ROLE-PROCESS MATRIX] Successfully recalculated role-competency matrix for org {organization_id}")

        return jsonify({
            'message': 'Role-process matrix updated successfully',
            'recalculated': True
        }), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error updating role-process matrix: {str(e)}")
        traceback.print_exc()
        return jsonify({'error': 'Failed to update role-process matrix'}), 500


@main_bp.route('/competencies', methods=['GET'])
def get_competencies_for_matrix():
    """Get all competencies for admin matrix editing"""
    try:
        competencies = Competency.query.all()

        return jsonify([c.to_dict() for c in competencies]), 200

    except Exception as e:
        current_app.logger.error(f"Error fetching competencies: {str(e)}")
        return jsonify({'error': 'Failed to fetch competencies'}), 500


@main_bp.route('/process_competency_matrix/<int:competency_id>', methods=['GET'])
def get_process_competency_matrix(competency_id):
    """Get process-competency matrix values for a specific competency"""
    try:
        # Get all processes
        processes = IsoProcesses.query.all()

        # Get matrix entries for this competency
        matrix_entries = ProcessCompetencyMatrix.query.filter_by(
            competency_id=competency_id
        ).all()

        return jsonify({
            'processes': [p.to_dict() for p in processes],
            'matrix': [entry.to_dict() for entry in matrix_entries]
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error fetching process-competency matrix: {str(e)}")
        return jsonify({'error': 'Failed to fetch process-competency matrix'}), 500


@main_bp.route('/process_competency_matrix/bulk', methods=['PUT'])
def bulk_update_process_competency_matrix():
    """
    Bulk update process-competency matrix and recalculate for ALL organizations
    Based on Derik's implementation (routes.py:322-328)
    """
    try:
        data = request.get_json()
        competency_id = data.get('competency_id')
        matrix = data.get('matrix')  # Dict: {process_id: value}

        if not all([competency_id, matrix]):
            return jsonify({'error': 'Missing required fields'}), 400

        # Update or create matrix entries
        for process_id, value in matrix.items():
            process_id = int(process_id)

            # Find existing entry or create new one
            entry = ProcessCompetencyMatrix.query.filter_by(
                iso_process_id=process_id,
                competency_id=competency_id
            ).first()

            if entry:
                entry.process_competency_value = value
            else:
                entry = ProcessCompetencyMatrix(
                    iso_process_id=process_id,
                    competency_id=competency_id,
                    process_competency_value=value
                )
                db.session.add(entry)

        db.session.commit()

        # Recalculate role-competency matrix for ALL organizations
        # As per MATRIX_CALCULATION_PATTERN.md
        organizations = Organization.query.all()
        for org in organizations:
            db.session.execute(
                text('CALL update_role_competency_matrix(:org_id);'),
                {'org_id': org.id}
            )
        db.session.commit()

        return jsonify({
            'message': 'Process-competency matrix updated successfully',
            'recalculated_for_orgs': len(organizations)
        }), 200

    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error updating process-competency matrix: {str(e)}")
        traceback.print_exc()
        return jsonify({'error': 'Failed to update process-competency matrix'}), 500


# =============================================================================
# QUESTIONNAIRE ENDPOINTS
# =============================================================================

@main_bp.route('/questionnaires/<int:questionnaire_id>', methods=['GET'])
def get_questionnaire_definition(questionnaire_id):
    """Get questionnaire definition (stub for now)"""
    try:
        # Stub implementation - return empty questionnaire structure
        # This can be expanded later with actual questionnaire data
        return jsonify({
            'id': questionnaire_id,
            'name': f'Questionnaire {questionnaire_id}',
            'questions': [],
            'description': 'Questionnaire definition'
        }), 200

    except Exception as e:
        current_app.logger.error(f"Error getting questionnaire: {str(e)}")
        return jsonify({'error': 'Failed to get questionnaire'}), 500


# =============================================================================
# DERIK'S COMPETENCY ASSESSMENT ENDPOINTS
# Legacy endpoints for competency assessment bridge compatibility
# =============================================================================

# REMOVED Phase 2B (2025-10-26): Legacy endpoint /new_survey_user
# Replaced by /assessment/start endpoint in main assessment flow
# Used deprecated NewSurveyUser model (removed from models.py)
# @main_bp.route('/new_survey_user', methods=['POST'])
# def create_new_survey_user():
#     """Create a new survey user for competency assessment"""
#     ...


@main_bp.route('/get_required_competencies_for_roles', methods=['POST'])
def get_required_competencies_for_roles():
    """Fetch distinct competencies and the maximum competency value for selected roles and organization."""
    from sqlalchemy import func

    data = request.json
    role_ids = data.get('role_ids')
    organization_id = data.get('organization_id')
    user_name = data.get('user_name')
    survey_type = data.get('survey_type')

    print(f"[get_required_competencies_for_roles] Role IDs: {role_ids}")
    print(f"[get_required_competencies_for_roles] Organization ID: {organization_id}")
    print(f"[get_required_competencies_for_roles] Survey type: {survey_type}")

    if survey_type == 'known_roles':
        if role_ids is None or organization_id is None:
            return jsonify({"error": "role_ids and organization_id are required"}), 400

        try:
            # Query with JOIN to get full competency details
            competencies = (
                db.session.query(
                    RoleCompetencyMatrix.competency_id,
                    Competency.competency_name,
                    Competency.description,
                    Competency.competency_area,
                    func.max(RoleCompetencyMatrix.role_competency_value).label('max_value')
                )
                .join(Competency, RoleCompetencyMatrix.competency_id == Competency.id)
                .filter(
                    RoleCompetencyMatrix.role_cluster_id.in_(role_ids),
                    RoleCompetencyMatrix.organization_id == organization_id
                )
                .group_by(
                    RoleCompetencyMatrix.competency_id,
                    Competency.competency_name,
                    Competency.description,
                    Competency.competency_area
                )
                .having(func.max(RoleCompetencyMatrix.role_competency_value) > 0)  # Filter out zero-level competencies
                .order_by(RoleCompetencyMatrix.competency_id)
                .all()
            )

            competencies_data = [
                {
                    'competency_id': competency.competency_id,
                    'competency_name': competency.competency_name,
                    'description': competency.description,
                    'category': competency.competency_area,  # Map to 'category' for frontend compatibility
                    'max_value': competency.max_value
                }
                for competency in competencies
            ]

            print(f"[get_required_competencies_for_roles] Filtered {len(competencies_data)} competencies with required level > 0")
            return jsonify({
                "success": True,
                "competencies": competencies_data,
                "count": len(competencies_data)
            }), 200

        except Exception as e:
            print(f"[get_required_competencies_for_roles] Error: {str(e)}")
            return jsonify({"error": str(e)}), 500

    elif survey_type == 'unknown_roles':
        if user_name is None or organization_id is None:
            return jsonify({"error": "user_name and organization_id are required"}), 400

        try:
            # Query with JOIN to get full competency details (same as known_roles fix)
            competencies = (
                db.session.query(
                    UnknownRoleCompetencyMatrix.competency_id,
                    Competency.competency_name,
                    Competency.description,
                    Competency.competency_area,
                    UnknownRoleCompetencyMatrix.role_competency_value.label('max_value')
                )
                .join(Competency, UnknownRoleCompetencyMatrix.competency_id == Competency.id)
                .filter(
                    UnknownRoleCompetencyMatrix.user_name == user_name,
                    UnknownRoleCompetencyMatrix.organization_id == organization_id,
                    UnknownRoleCompetencyMatrix.role_competency_value > 0  # Filter out zero-level competencies
                )
                .order_by(UnknownRoleCompetencyMatrix.competency_id)
                .all()
            )

            competencies_data = [
                {
                    'competency_id': competency.competency_id,
                    'competency_name': competency.competency_name,
                    'description': competency.description,
                    'category': competency.competency_area,  # Map to 'category' for frontend compatibility
                    'max_value': competency.max_value
                }
                for competency in competencies
            ]

            print(f"[get_required_competencies_for_roles] Task-based: Filtered {len(competencies_data)} competencies with required level > 0")
            return jsonify({"competencies": competencies_data}), 200

        except Exception as e:
            print(f"[get_required_competencies_for_roles] Error: {str(e)}")
            return jsonify({"error": str(e)}), 500

    elif survey_type == "all_roles":
        print("[get_required_competencies_for_roles] Fetching competencies for all roles")
        if organization_id is None:
            return jsonify({"error": "organization_id is required"}), 400

        try:
            competencies = (
                db.session.query(
                    RoleCompetencyMatrix.competency_id,
                    func.round(func.avg(RoleCompetencyMatrix.role_competency_value)).label('max_value')
                )
                .filter(
                    RoleCompetencyMatrix.organization_id == organization_id
                )
                .group_by(RoleCompetencyMatrix.competency_id)
                .having(func.round(func.avg(RoleCompetencyMatrix.role_competency_value)) > 0)  # Filter out zero-level competencies
                .order_by(RoleCompetencyMatrix.competency_id)
                .all()
            )

            competencies_data = [
                {
                    'competency_id': competency.competency_id,
                    'max_value': competency.max_value
                }
                for competency in competencies
            ]

            print(f"[get_required_competencies_for_roles] Filtered {len(competencies_data)} competencies with required level > 0")
            return jsonify({
                "success": True,
                "competencies": competencies_data,
                "count": len(competencies_data)
            }), 200

        except Exception as e:
            print(f"[get_required_competencies_for_roles] Error: {str(e)}")
            return jsonify({"error": str(e)}), 500

    return jsonify({"error": "Invalid survey_type"}), 400


# =============================================================================
# DERIK'S COMPETENCY ASSESSMENT ENDPOINTS (Phase 2 Integration)
# =============================================================================

@main_bp.route('/get_competency_indicators_for_competency/<int:competency_id>', methods=['GET'])
def get_competency_indicators_for_competency(competency_id):
    """
    Fetch all indicators associated with the specified competency, grouped by level.
    Used by Phase 2 competency assessment to display indicators for each competency.
    """
    try:
        # Query to fetch indicators by competency ID
        indicators = CompetencyIndicator.query.filter_by(competency_id=competency_id).all()

        # Group indicators by their level
        indicators_by_level = {}
        for indicator in indicators:
            if indicator.level not in indicators_by_level:
                indicators_by_level[indicator.level] = []
            indicators_by_level[indicator.level].append({
                "indicator_en": indicator.indicator_en,
                "indicator_de": indicator.indicator_de
            })

        # Structure response with indicators grouped by level
        response_data = [
            {
                "level": level,
                "indicators": indicators
            }
            for level, indicators in indicators_by_level.items()
        ]

        return jsonify(response_data), 200

    except Exception as e:
        print(f"[get_competency_indicators] Error: {str(e)}")
        return jsonify({"error": "An error occurred while fetching competency indicators"}), 500


# Note: /findProcesses endpoint already exists at line ~1587 in this file
# No need for duplicate implementation here


# =============================================================================
# NEW AUTHENTICATED ASSESSMENT ENDPOINTS (Replaces anonymous survey system)
# =============================================================================

@main_bp.route('/assessment/start', methods=['POST'])
def start_assessment():
    """
    Start a new assessment for an authenticated user
    Replaces /new_survey_user endpoint - uses real authenticated user instead of anonymous username
    """
    from models import UserAssessment, User

    data = request.get_json()
    try:
        user_id = data.get('user_id')
        organization_id = data.get('organization_id')
        assessment_type = data.get('assessment_type')  # 'role_based', 'task_based', 'full_competency'

        if not user_id or not organization_id or not assessment_type:
            return jsonify({"error": "user_id, organization_id, and assessment_type are required"}), 400

        # Verify user exists
        user = User.query.get(user_id)
        if not user:
            return jsonify({"error": "User not found"}), 404

        # Determine survey_type based on assessment_type
        survey_type_map = {
            'role_based': 'known_roles',
            'task_based': 'unknown_roles',
            'full_competency': 'all_roles'
        }
        survey_type = survey_type_map.get(assessment_type, 'known_roles')

        # Create new assessment record
        assessment = UserAssessment(
            user_id=user_id,
            organization_id=organization_id,
            assessment_type=assessment_type,
            survey_type=survey_type
        )

        db.session.add(assessment)
        db.session.commit()
        db.session.refresh(assessment)

        print(f"[start_assessment] Created assessment {assessment.id} for user {user.username}")

        return jsonify({
            "message": "Assessment started successfully",
            "assessment_id": assessment.id,
            "username": user.username,  # Return for compatibility
            "user_id": user.id,
            "assessment": assessment.to_dict()
        }), 201

    except Exception as e:
        print(f"[start_assessment] Error: {str(e)}")
        db.session.rollback()
        return jsonify({"error": "An error occurred", "details": str(e)}), 500


@main_bp.route('/phase2/start-assessment', methods=['POST'])
def start_phase2_assessment():
    """
    Start a new Phase 2 assessment (task-based or role-based pathway)

    Expected payload:
    - org_id: Organization ID
    - admin_user_id: ID of user taking assessment
    - employee_name: Name of employee (optional)
    - role_ids: Array of selected role IDs (empty for task-based)
    - competencies: Array of necessary competencies
    - assessment_type: 'phase2_employee' or other
    - task_based_username: Username for task-based pathway (optional)
    """
    from models import UserAssessment, User

    data = request.get_json()
    try:
        org_id = data.get('org_id')
        admin_user_id = data.get('admin_user_id')
        employee_name = data.get('employee_name')
        role_ids = data.get('role_ids', [])
        competencies = data.get('competencies', [])
        assessment_type = data.get('assessment_type', 'phase2_employee')
        task_based_username = data.get('task_based_username')

        if not org_id or not admin_user_id:
            return jsonify({"error": "org_id and admin_user_id are required"}), 400

        # Verify user exists
        user = User.query.get(admin_user_id)
        if not user:
            return jsonify({"error": "User not found"}), 404

        # Determine survey_type based on pathway
        survey_type = 'unknown_roles' if task_based_username else 'known_roles'

        # Prepare tasks_responsibilities JSON for task-based pathway
        tasks_data = None
        if task_based_username:
            tasks_data = {
                'username': task_based_username,
                'competencies': competencies
            }

        # Create new assessment record
        assessment = UserAssessment(
            user_id=admin_user_id,
            organization_id=org_id,
            assessment_type=assessment_type,
            survey_type=survey_type,
            selected_roles=role_ids if role_ids else None,
            tasks_responsibilities=tasks_data
        )

        db.session.add(assessment)
        db.session.commit()
        db.session.refresh(assessment)

        print(f"[start_phase2_assessment] Created assessment {assessment.id} for user {user.username}")
        print(f"[start_phase2_assessment] Survey type: {survey_type}, Task-based username: {task_based_username}")

        return jsonify({
            "success": True,
            "message": "Assessment started successfully",
            "assessment_id": assessment.id,
            "username": user.username,
            "survey_type": survey_type,
            "task_based_username": task_based_username
        }), 201

    except Exception as e:
        print(f"[start_phase2_assessment] Error: {str(e)}")
        db.session.rollback()
        return jsonify({"success": False, "error": "An error occurred", "details": str(e)}), 500


@main_bp.route('/phase2/submit-assessment', methods=['POST'])
def submit_phase2_assessment():
    """
    Submit Phase 2 competency assessment answers

    Expected payload:
    - assessment_id: Assessment ID
    - answers: Array of {competency_id, selected_groups, current_level}

    Returns:
    - Success status and assessment ID
    """
    from models import UserAssessment, UserCompetencySurveyResults
    from datetime import datetime

    data = request.get_json()
    try:
        assessment_id = data.get('assessment_id')
        answers = data.get('answers', [])

        if not assessment_id:
            return jsonify({"success": False, "error": "assessment_id is required"}), 400

        # Fetch the assessment
        assessment = UserAssessment.query.get(assessment_id)
        if not assessment:
            return jsonify({"success": False, "error": "Assessment not found"}), 404

        print(f"[submit_phase2_assessment] Submitting {len(answers)} answers for assessment {assessment_id}")

        # Delete existing survey results for this assessment
        UserCompetencySurveyResults.query.filter_by(
            user_id=assessment.user_id,
            assessment_id=assessment_id
        ).delete()

        # Insert new survey results
        for answer in answers:
            competency_id = answer.get('competency_id')
            current_level = answer.get('current_level', 0)

            if competency_id is None:
                continue

            survey_result = UserCompetencySurveyResults(
                user_id=assessment.user_id,
                organization_id=assessment.organization_id,
                competency_id=competency_id,
                score=current_level,
                assessment_id=assessment_id
            )
            db.session.add(survey_result)
            print(f"[submit_phase2_assessment] Added result: competency {competency_id}, score {current_level}")

        # Mark assessment as completed
        assessment.completed_at = datetime.utcnow()

        # Populate user_role_cluster table for role-based pathway
        # This is required for learning objectives to detect high-maturity organizations
        print(f"[submit_phase2_assessment] DEBUG: survey_type='{assessment.survey_type}', selected_roles={assessment.selected_roles}")
        print(f"[submit_phase2_assessment] DEBUG: survey_type check: {assessment.survey_type == 'known_roles'}")
        print(f"[submit_phase2_assessment] DEBUG: selected_roles bool: {bool(assessment.selected_roles)}")
        if assessment.survey_type == 'known_roles' and assessment.selected_roles:
            from models import UserRoleCluster

            # Delete existing role assignments for this assessment
            UserRoleCluster.query.filter_by(assessment_id=assessment_id).delete()

            # Insert new role assignments
            for role_id in assessment.selected_roles:
                role_entry = UserRoleCluster(
                    user_id=assessment.user_id,
                    role_cluster_id=role_id,
                    assessment_id=assessment_id
                )
                db.session.add(role_entry)
                print(f"[submit_phase2_assessment] Added role {role_id} to user_role_cluster for user {assessment.user_id}")

        db.session.commit()

        print(f"[submit_phase2_assessment] Assessment {assessment_id} completed successfully")

        # After saving, fetch results with gap analysis using existing get_assessment_results logic
        # This provides immediate feedback to the user and enables caching for future visits
        try:
            from models import Competency, UnknownRoleCompetencyMatrix, RoleCompetencyMatrix, UserRoleCluster, User

            # Fetch user competencies
            print(f"[submit_phase2_assessment] Fetching competencies for assessment_id={assessment_id}")
            user_competencies = UserCompetencySurveyResults.query.filter_by(
                assessment_id=assessment_id
            ).order_by(UserCompetencySurveyResults.competency_id).all()

            print(f"[submit_phase2_assessment] Found {len(user_competencies)} user competencies")

            competencies = Competency.query.filter(
                Competency.id.in_([u.competency_id for u in user_competencies])
            ).order_by(Competency.id).all()

            competency_info_map = {comp.id: {'name': comp.competency_name, 'area': comp.competency_area} for comp in competencies}

            user_scores = [
                {
                    'competency_id': u.competency_id,
                    'score': u.score,
                    'competency_name': competency_info_map[u.competency_id]['name'],
                    'competency_area': competency_info_map[u.competency_id]['area']
                }
                for u in user_competencies
            ]

            # Fetch required scores based on survey type
            if assessment.survey_type == 'known_roles':
                # Use selected_roles from assessment (not UserRoleCluster)
                role_cluster_ids = assessment.selected_roles or []

                if not role_cluster_ids:
                    print(f"[submit_phase2_assessment] WARNING: No role IDs found in assessment.selected_roles")
                    max_scores = []
                else:
                    print(f"[submit_phase2_assessment] Role-based pathway: role_ids={role_cluster_ids}, org_id={assessment.organization_id}")
                    max_scores = db.session.query(
                        RoleCompetencyMatrix.competency_id,
                        db.func.max(RoleCompetencyMatrix.role_competency_value).label('max_score')
                    ).filter(
                        RoleCompetencyMatrix.organization_id == assessment.organization_id,
                        RoleCompetencyMatrix.role_cluster_id.in_(role_cluster_ids)
                    ).group_by(RoleCompetencyMatrix.competency_id).having(
                        db.func.max(RoleCompetencyMatrix.role_competency_value) > 0
                    ).order_by(RoleCompetencyMatrix.competency_id).all()
                    print(f"[submit_phase2_assessment] Found {len(max_scores)} required competencies from role_competency_matrix")

            elif assessment.survey_type == 'unknown_roles':
                # For task-based pathway - get username from tasks_responsibilities JSON
                task_based_username = assessment.tasks_responsibilities.get('username') if assessment.tasks_responsibilities else None

                if not task_based_username:
                    print(f"[submit_phase2_assessment] ERROR: No task-based username found in assessment {assessment_id}")
                    raise Exception("Task-based username not found in assessment")

                print(f"[submit_phase2_assessment] Task-based pathway: task_username={task_based_username}, org_id={assessment.organization_id}")
                max_scores = db.session.query(
                    UnknownRoleCompetencyMatrix.competency_id,
                    UnknownRoleCompetencyMatrix.role_competency_value.label('max_score')
                ).filter(
                    UnknownRoleCompetencyMatrix.organization_id == assessment.organization_id,
                    UnknownRoleCompetencyMatrix.user_name == task_based_username,
                    UnknownRoleCompetencyMatrix.role_competency_value > 0
                ).all()
                print(f"[submit_phase2_assessment] Found {len(max_scores)} required competencies from unknown_role_competency_matrix")
            else:
                max_scores = []

            max_scores_dict = [{'competency_id': m.competency_id, 'max_score': float(m.max_score)} for m in max_scores]

            # Filter user_scores to only include competencies with required level > 0
            required_competency_ids = {m['competency_id'] for m in max_scores_dict}
            print(f"[submit_phase2_assessment] Required competency IDs: {required_competency_ids}")
            user_scores = [score for score in user_scores if score['competency_id'] in required_competency_ids]
            print(f"[submit_phase2_assessment] Filtered user_scores to {len(user_scores)} competencies")

            # Calculate summary statistics
            total_competencies = len(user_scores)
            proficient = 0
            needs_improvement = 0

            for score in user_scores:
                comp_id = score['competency_id']
                current_level = score['score']
                required_level = next((m['max_score'] for m in max_scores_dict if m['competency_id'] == comp_id), 0)

                if current_level >= required_level:
                    proficient += 1
                else:
                    needs_improvement += 1

            print(f"[submit_phase2_assessment] Gap analysis: {proficient}/{total_competencies} proficient, {needs_improvement} need improvement")

            return jsonify({
                "success": True,
                "message": "Assessment submitted successfully",
                "assessment_id": assessment_id,
                "results": {
                    "assessment_id": assessment_id,  # Add for CompetencyResults compatibility
                    "assessment": assessment.to_dict(),
                    "user_scores": user_scores,
                    "max_scores": max_scores_dict,
                    "feedback_list": []  # Will be generated on first results page visit
                },
                "summary": {
                    "total": total_competencies,
                    "proficient": proficient,
                    "needs_improvement": needs_improvement
                }
            }), 200

        except Exception as results_error:
            print(f"[submit_phase2_assessment] Error generating results: {str(results_error)}")
            import traceback
            traceback.print_exc()
            # Still return success for submission, but without results
            return jsonify({
                "success": True,
                "message": "Assessment submitted successfully, but results generation failed",
                "assessment_id": assessment_id
            }), 200

    except Exception as e:
        print(f"[submit_phase2_assessment] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        db.session.rollback()
        return jsonify({"success": False, "error": "An error occurred", "details": str(e)}), 500


@main_bp.route('/phase2/role-based-pathway/<int:organization_id>', methods=['GET'])
def get_role_based_pathway_analysis(organization_id):
    """
    Run complete role-based pathway analysis (8-step algorithm)

    This endpoint executes the complete algorithm including:
    - Steps 1-4: Data retrieval, analysis, aggregation, best-fit selection
    - Steps 5-8: Validation, strategic decisions, objectives, output

    Args:
        organization_id: Organization ID to analyze

    Returns:
        Complete analysis with:
        - Cross-strategy coverage
        - Strategy validation
        - Strategic decisions and recommendations
        - Learning objectives per strategy
    """
    try:
        from app.services.role_based_pathway_fixed import run_role_based_pathway_analysis_fixed

        print(f"[role-based-pathway] Starting analysis for organization {organization_id}")

        # Run the complete 8-step algorithm
        result = run_role_based_pathway_analysis_fixed(organization_id)

        # Check for errors
        if 'error' in result:
            print(f"[role-based-pathway] Error: {result['error']}")
            return jsonify({"success": False, "error": result['error']}), 400

        print(f"[role-based-pathway] Analysis complete for organization {organization_id}")
        print(f"[role-based-pathway] Validation status: {result['strategy_validation']['status']}")
        print(f"[role-based-pathway] Recommendation: {result['strategic_decisions']['overall_action']}")

        return jsonify({
            "success": True,
            "data": result
        }), 200

    except Exception as e:
        print(f"[role-based-pathway] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": "An error occurred", "details": str(e)}), 500


@main_bp.route('/assessment/<int:assessment_id>/submit', methods=['POST'])
def submit_assessment(assessment_id):
    """
    Submit competency scores for an assessment
    Replaces /submit_survey endpoint - uses assessment_id instead of username
    """
    from models import UserAssessment, User, UserCompetencySurveyResults, UserRoleCluster

    data = request.get_json()
    try:
        # Fetch the assessment
        assessment = UserAssessment.query.get(assessment_id)
        if not assessment:
            return jsonify({"error": "Assessment not found"}), 404

        # Extract data
        selected_roles = data.get('selected_roles', [])
        competency_scores = data.get('competency_scores', [])
        tasks_responsibilities = data.get('tasks_responsibilities')

        # Update assessment with submitted data
        assessment.selected_roles = selected_roles
        assessment.tasks_responsibilities = tasks_responsibilities
        assessment.completed_at = datetime.utcnow()

        # Delete existing roles for this assessment if any
        UserRoleCluster.query.filter_by(assessment_id=assessment_id).delete()

        # Insert new roles with assessment_id
        # After migration 003: role_cluster_id now references organization_roles.id directly
        # Supports both standard-derived AND custom roles
        for role in selected_roles:
            org_role_id = role.get('role_id') or role.get('id')

            role_entry = UserRoleCluster(
                user_id=assessment.user_id,
                role_cluster_id=org_role_id,  # Now directly uses organization_roles.id
                assessment_id=assessment_id
            )
            db.session.add(role_entry)
            print(f"[submit_assessment] Added role {org_role_id} for assessment {assessment_id}")

        # Delete existing survey results for this assessment
        UserCompetencySurveyResults.query.filter_by(
            user_id=assessment.user_id,
            assessment_id=assessment_id
        ).delete()

        # Define valid competency scores (aligned with learning objectives templates)
        VALID_SCORES = [0, 1, 2, 4, 6]

        # Insert survey results with assessment_id
        for competency in competency_scores:
            # Extract score with proper fallback to 0 for None values
            score = competency.get('user_score') if competency.get('user_score') is not None else competency.get('score')
            if score is None:
                score = 0  # Default to 0 if no score provided

            # Validate score is one of the allowed values
            if score not in VALID_SCORES:
                return jsonify({
                    "error": f"Invalid competency score: {score}. Valid scores are {VALID_SCORES}.",
                    "competency_id": competency.get('competency_id') or competency.get('competencyId'),
                    "invalid_score": score
                }), 400

            survey = UserCompetencySurveyResults(
                user_id=assessment.user_id,
                organization_id=assessment.organization_id,
                competency_id=competency.get('competency_id') or competency.get('competencyId'),
                score=score,
                assessment_id=assessment_id
            )
            db.session.add(survey)

        db.session.commit()

        print(f"[submit_assessment] Assessment {assessment_id} completed for user {assessment.user_id}")

        return jsonify({
            'message': 'Assessment submitted successfully',
            'assessment_id': assessment_id,
            'assessment': assessment.to_dict()
        }), 200

    except Exception as e:
        print(f"[submit_assessment] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        db.session.rollback()
        return jsonify({"error": "An error occurred", "details": str(e)}), 500


@main_bp.route('/assessment/<int:assessment_id>/results', methods=['GET'])
def get_assessment_results(assessment_id):
    """
    Get results for a specific assessment
    Replaces /get_user_competency_results endpoint - uses assessment_id instead of username
    """
    from models import (UserAssessment, UserCompetencySurveyResults, Competency,
                       UserRoleCluster, RoleCompetencyMatrix, UnknownRoleCompetencyMatrix,
                       UserCompetencySurveyFeedback)

    try:
        # Fetch the assessment
        assessment = UserAssessment.query.get(assessment_id)
        if not assessment:
            return jsonify({'error': 'Assessment not found'}), 404

        # Fetch competency survey results for this assessment
        user_competencies = UserCompetencySurveyResults.query.filter_by(
            assessment_id=assessment_id
        ).order_by(UserCompetencySurveyResults.competency_id).all()

        if not user_competencies:
            return jsonify({'error': 'No results found for this assessment'}), 404

        competencies = Competency.query.filter(
            Competency.id.in_([u.competency_id for u in user_competencies])
        ).order_by(Competency.id).all()

        competency_info_map = {comp.id: {'name': comp.competency_name, 'area': comp.competency_area} for comp in competencies}

        user_scores = [
            {
                'competency_id': u.competency_id,
                'score': u.score,
                'competency_name': competency_info_map[u.competency_id]['name'],
                'competency_area': competency_info_map[u.competency_id]['area']
            }
            for u in user_competencies
        ]

        # Fetch required competency scores based on survey type
        if assessment.survey_type == 'known_roles':
            # Use selected_roles from assessment (not UserRoleCluster)
            role_cluster_ids = assessment.selected_roles or []

            if not role_cluster_ids:
                print(f"[get_assessment_results] WARNING: No role IDs found in assessment.selected_roles")
                max_scores = []
            else:
                print(f"[get_assessment_results] Role-based pathway: role_ids={role_cluster_ids}, org_id={assessment.organization_id}")
                max_scores = db.session.query(
                    RoleCompetencyMatrix.competency_id,
                    db.func.max(RoleCompetencyMatrix.role_competency_value).label('max_score')
                ).filter(
                    RoleCompetencyMatrix.organization_id == assessment.organization_id,
                    RoleCompetencyMatrix.role_cluster_id.in_(role_cluster_ids)
                ).group_by(RoleCompetencyMatrix.competency_id).having(
                    db.func.max(RoleCompetencyMatrix.role_competency_value) > 0
                ).order_by(RoleCompetencyMatrix.competency_id).all()
                print(f"[get_assessment_results] Found {len(max_scores)} required competencies from role_competency_matrix")

        elif assessment.survey_type == 'unknown_roles':
            # For task-based, fetch from UnknownRoleCompetencyMatrix using task-based username
            task_based_username = assessment.tasks_responsibilities.get('username') if assessment.tasks_responsibilities else None

            if not task_based_username:
                print(f"[get_assessment_results] ERROR: No task-based username found for assessment {assessment_id}")
                return jsonify({'error': 'Task-based username not found'}), 500

            max_scores = db.session.query(
                UnknownRoleCompetencyMatrix.competency_id,
                UnknownRoleCompetencyMatrix.role_competency_value.label('max_score')
            ).filter(
                UnknownRoleCompetencyMatrix.organization_id == assessment.organization_id,
                UnknownRoleCompetencyMatrix.user_name == task_based_username,
                UnknownRoleCompetencyMatrix.role_competency_value > 0
            ).all()

        elif assessment.survey_type == 'all_roles':
            max_scores = db.session.query(
                RoleCompetencyMatrix.competency_id,
                db.func.avg(RoleCompetencyMatrix.role_competency_value).label('max_score')
            ).filter(
                RoleCompetencyMatrix.organization_id == assessment.organization_id
            ).group_by(RoleCompetencyMatrix.competency_id).having(
                db.func.avg(RoleCompetencyMatrix.role_competency_value) > 0
            ).order_by(RoleCompetencyMatrix.competency_id).all()
        else:
            max_scores = []

        max_scores_dict = [{'competency_id': m.competency_id, 'max_score': float(m.max_score)} for m in max_scores]

        # Filter user_scores to only include competencies with required level > 0
        required_competency_ids = {m['competency_id'] for m in max_scores_dict}
        user_scores = [score for score in user_scores if score['competency_id'] in required_competency_ids]

        # Check if feedback already exists for this assessment
        existing_feedbacks = UserCompetencySurveyFeedback.query.filter_by(
            assessment_id=assessment_id
        ).all()

        if existing_feedbacks:
            # Since feedback is stored as a JSONB array in a single row, extract it directly
            # The feedback column contains the complete feedback_list, not individual items
            if len(existing_feedbacks) == 1:
                feedback_list = existing_feedbacks[0].feedback
            else:
                # Fallback: flatten if multiple rows (shouldn't happen with current schema)
                feedback_list = []
                for fb in existing_feedbacks:
                    if isinstance(fb.feedback, list):
                        feedback_list.extend(fb.feedback)
                    else:
                        feedback_list.append(fb.feedback)
            print(f"[get_assessment_results] Using cached feedback for assessment {assessment_id}")
        else:
            # Generate feedback using LLM
            print(f"[get_assessment_results] No cached feedback found for assessment {assessment_id}, generating...")
            feedback_list = []

            try:
                from collections import defaultdict
                from models import CompetencyIndicator
                from app.generate_survey_feedback import generate_feedback_with_llm

                # Helper function to map score to level
                def score_to_level(score):
                    score_map = {
                        0: '0',  # unwissend (unaware)
                        1: '1',  # kennen (know)
                        2: '2',  # verstehen (understand)
                        4: '3',  # anwenden (apply)
                        6: '4'   # beherrschen (master)
                    }
                    return score_map.get(score, '0')

                # Helper function to get level name
                def get_level_name(level):
                    level_names = {
                        '0': 'unwissend (unaware)',
                        '1': 'kennen (know)',
                        '2': 'verstehen (understand)',
                        '3': 'anwenden (apply)',
                        '4': 'beherrschen (master)'
                    }
                    return level_names.get(level, 'unknown')

                # Helper function to get indicators for a competency at a specific level
                def get_indicators_for_level(competency_id, level):
                    if level == '0':
                        return 'You are unaware or lack knowledge in this competency area'

                    indicators = CompetencyIndicator.query.filter_by(
                        competency_id=competency_id,
                        level=level
                    ).all()

                    if not indicators:
                        return f'No specific indicators available for level {level} ({get_level_name(level)})'

                    return '. '.join([ind.indicator_en for ind in indicators if ind.indicator_en])

                # Build max_scores_map for easy lookup
                max_scores_map = {m['competency_id']: m['max_score'] for m in max_scores_dict}

                # Build detailed competency results
                aggregated_results = defaultdict(list)

                for user_comp in user_competencies:
                    competency_id = user_comp.competency_id
                    user_score = user_comp.score

                    # Get competency info
                    competency_obj = Competency.query.get(competency_id)
                    if not competency_obj:
                        continue

                    competency_name = competency_obj.competency_name
                    competency_area = competency_obj.competency_area

                    # Map user score to level
                    user_level = score_to_level(user_score)
                    user_indicators = get_indicators_for_level(competency_id, user_level)

                    # Get required score and map to level
                    required_score = max_scores_map.get(competency_id, 0)

                    # Skip competencies with required level = 0
                    if required_score == 0:
                        continue

                    required_level = score_to_level(int(required_score)) if required_score else 'unwissend'
                    required_indicators = get_indicators_for_level(competency_id, required_level)

                    # Add to aggregated results
                    aggregated_results[competency_area].append({
                        "competency_name": competency_name,
                        "user_level": user_level,
                        "user_indicator": user_indicators,
                        "required_level": required_level,
                        "required_indicator": required_indicators
                    })

                print(f"[get_assessment_results] Aggregated {len(aggregated_results)} areas for feedback generation")

                # Generate feedback using LLM for each competency area
                for competency_area, competencies in aggregated_results.items():
                    print(f"[get_assessment_results] Generating feedback for {competency_area} with {len(competencies)} competencies")
                    feedback_json = generate_feedback_with_llm(competency_area, competencies)
                    feedback_list.append(feedback_json)

                # Save feedback to database with assessment_id
                new_feedback = UserCompetencySurveyFeedback(
                    user_id=assessment.user_id,
                    organization_id=assessment.organization_id,
                    feedback=feedback_list,
                    assessment_id=assessment_id
                )
                db.session.add(new_feedback)
                db.session.commit()
                print(f"[get_assessment_results] Generated and saved {len(feedback_list)} feedback items for assessment {assessment_id}")

            except Exception as e:
                db.session.rollback()
                print(f"[get_assessment_results] LLM feedback generation error: {str(e)}")
                import traceback
                traceback.print_exc()
                feedback_list = []  # Return empty feedback on error

        # Get full role objects for selected roles (for display in results)
        selected_roles_data = []
        if assessment.selected_roles and assessment.survey_type == 'known_roles':
            from models import OrganizationRoles
            roles = OrganizationRoles.query.filter(
                OrganizationRoles.id.in_(assessment.selected_roles)
            ).all()
            selected_roles_data = [role.to_dict() for role in roles]
            print(f"[get_assessment_results] Fetched {len(selected_roles_data)} role objects for display")

        return jsonify({
            'assessment': assessment.to_dict(),
            'user_scores': user_scores,
            'max_scores': max_scores_dict,
            'feedback_list': feedback_list,
            'selected_roles_data': selected_roles_data  # Full role objects for frontend display
        }), 200

    except Exception as e:
        print(f"[get_assessment_results] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': 'An error occurred', 'details': str(e)}), 500


@main_bp.route('/user/<int:user_id>/assessments', methods=['GET'])
def get_user_assessment_history(user_id):
    """
    Get all assessments for a user (assessment history)
    NEW endpoint - enables users to see their assessment history
    """
    from models import UserAssessment, User

    try:
        # Verify user exists
        user = User.query.get(user_id)
        if not user:
            return jsonify({'error': 'User not found'}), 404

        # Fetch all assessments for this user
        assessments = UserAssessment.query.filter_by(user_id=user_id).order_by(
            UserAssessment.created_at.desc()
        ).all()

        assessments_list = [assessment.to_dict() for assessment in assessments]

        print(f"[get_user_assessment_history] Found {len(assessments_list)} assessments for user {user.username}")

        return jsonify({
            'user_id': user_id,
            'username': user.username,
            'assessment_count': len(assessments_list),
            'assessments': assessments_list
        }), 200

    except Exception as e:
        print(f"[get_user_assessment_history] Error: {str(e)}")
        return jsonify({'error': 'An error occurred', 'details': str(e)}), 500


# =============================================================================
# OLD ANONYMOUS SURVEY ENDPOINTS (Keep for backward compatibility during migration)
# =============================================================================

# REMOVED Phase 2B (2025-10-26): Legacy endpoint /submit_survey
# Replaced by /assessment/<id>/submit endpoint in main assessment flow
# Used deprecated AppUser, NewSurveyUser, UserSurveyType models (removed from models.py)
# @main_bp.route('/submit_survey', methods=['POST'])
# def submit_survey():
#     """Submit competency assessment survey results"""
#     ...


# REMOVED Phase 2B (2025-10-26): Legacy endpoint /get_user_competency_results
# Replaced by /assessment/<id>/results endpoint in main assessment flow
# Used deprecated AppUser model (removed from models.py)
# This was a 227-line function that generated competency feedback with LLM
# @main_bp.route('/get_user_competency_results', methods=['GET'])
# def get_user_competency_results():
#     """Get competency assessment results for a user"""
#     ...


@main_bp.route('/latest_competency_overview', methods=['GET'])
@jwt_required()
def get_latest_competency_overview():
    """
    Get top 5 competencies from user's latest Phase 2 assessment,
    sorted by required level (importance) from role-competency matrix.

    Returns competencies with highest required levels to show users
    what's most critical for their SE role.
    """
    from models import (UserAssessment, UserCompetencySurveyResults, Competency,
                       UserRoleCluster, RoleCompetencyMatrix, UnknownRoleCompetencyMatrix)

    try:
        user_id = int(get_jwt_identity())

        # Get user's latest completed Phase 2 assessment
        latest_assessment = UserAssessment.query.filter_by(
            user_id=user_id
        ).order_by(UserAssessment.created_at.desc()).first()

        if not latest_assessment:
            return jsonify({
                'competencies': [],
                'message': 'No Phase 2 assessment completed yet'
            }), 200

        # Get user's competency scores for this assessment
        user_competencies = UserCompetencySurveyResults.query.filter_by(
            assessment_id=latest_assessment.id
        ).all()

        print(f"[latest_competency_overview] Assessment {latest_assessment.id}: survey_type={latest_assessment.survey_type}, user_competencies={len(user_competencies)}")

        if not user_competencies:
            return jsonify({
                'competencies': [],
                'message': 'No competency data found'
            }), 200

        # Get competency info
        competency_ids = [uc.competency_id for uc in user_competencies]
        competencies = Competency.query.filter(
            Competency.id.in_(competency_ids)
        ).all()

        competency_info_map = {
            comp.id: {
                'name': comp.competency_name,
                'area': comp.competency_area
            }
            for comp in competencies
        }

        # Get required competency levels based on survey type
        if latest_assessment.survey_type == 'known_roles':
            # Use selected_roles from assessment (not UserRoleCluster)
            role_cluster_ids = latest_assessment.selected_roles or []

            if not role_cluster_ids:
                print(f"[latest_competency_overview] WARNING: No role IDs in assessment.selected_roles")
                max_scores = []
            else:
                print(f"[latest_competency_overview] Role-based: role_ids={role_cluster_ids}")
                # Get max required level across all user's roles
                max_scores = db.session.query(
                    RoleCompetencyMatrix.competency_id,
                    db.func.max(RoleCompetencyMatrix.role_competency_value).label('required_level')
                ).filter(
                    RoleCompetencyMatrix.organization_id == latest_assessment.organization_id,
                    RoleCompetencyMatrix.role_cluster_id.in_(role_cluster_ids)
                ).group_by(RoleCompetencyMatrix.competency_id).having(
                    db.func.max(RoleCompetencyMatrix.role_competency_value) > 0
                ).all()

        elif latest_assessment.survey_type == 'unknown_roles':
            # Get from task-based role mapping - use task_based_username from tasks_responsibilities JSON
            task_based_username = latest_assessment.tasks_responsibilities.get('username') if latest_assessment.tasks_responsibilities else None

            if not task_based_username:
                print(f"[latest_competency_overview] ERROR: No task-based username found in assessment {latest_assessment.id}")
                max_scores = []
            else:
                print(f"[latest_competency_overview] Task-based: task_username={task_based_username}, org_id={latest_assessment.organization_id}")
                max_scores = db.session.query(
                    UnknownRoleCompetencyMatrix.competency_id,
                    UnknownRoleCompetencyMatrix.role_competency_value.label('required_level')
                ).filter(
                    UnknownRoleCompetencyMatrix.organization_id == latest_assessment.organization_id,
                    UnknownRoleCompetencyMatrix.user_name == task_based_username,
                    UnknownRoleCompetencyMatrix.role_competency_value > 0
                ).all()
                print(f"[latest_competency_overview] Found {len(max_scores)} required competencies from unknown_role_competency_matrix")

        elif latest_assessment.survey_type == 'all_roles':
            # Average across all roles
            max_scores = db.session.query(
                RoleCompetencyMatrix.competency_id,
                db.func.avg(RoleCompetencyMatrix.role_competency_value).label('required_level')
            ).filter(
                RoleCompetencyMatrix.organization_id == latest_assessment.organization_id
            ).group_by(RoleCompetencyMatrix.competency_id).having(
                db.func.avg(RoleCompetencyMatrix.role_competency_value) > 0
            ).all()
        else:
            max_scores = []

        # Build map of required levels
        required_level_map = {m.competency_id: float(m.required_level) for m in max_scores}

        # Build combined data: user score + required level + competency info
        combined_data = []
        for uc in user_competencies:
            competency_id = uc.competency_id

            # Only include competencies with required level > 0
            if competency_id not in required_level_map:
                continue

            if competency_id not in competency_info_map:
                continue

            combined_data.append({
                'competency_id': competency_id,
                'competency_name': competency_info_map[competency_id]['name'],
                'competency_area': competency_info_map[competency_id]['area'],
                'current_score': uc.score,
                'required_score': required_level_map[competency_id],
                'gap': required_level_map[competency_id] - uc.score
            })

        # Sort by required level (importance) descending, then by gap descending
        combined_data.sort(key=lambda x: (-x['required_score'], -x['gap']))

        # Take top 5
        top_5_competencies = combined_data[:5]

        print(f"[get_latest_competency_overview] Returning {len(top_5_competencies)} competencies for user {user_id}")

        return jsonify({
            'competencies': top_5_competencies,
            'assessment_id': latest_assessment.id,
            'completed_at': latest_assessment.created_at.isoformat() if latest_assessment.created_at else None,
            'total_competencies': len(combined_data)
        }), 200

    except Exception as e:
        print(f"[get_latest_competency_overview] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


# =============================================================================
# PHASE 2 TASK 3: LEARNING OBJECTIVES GENERATION API ENDPOINTS
# =============================================================================

@main_bp.route('/phase2/learning-objectives/generate', methods=['POST'])
def api_generate_learning_objectives():
    """
    Generate learning objectives for an organization (Week 2 Implementation)

    This endpoint uses the new Design v5 implementation with all 8 algorithms:
    1. Calculate combined targets (separate TTT)
    2. Validate mastery requirements
    3. Detect gaps (role-based or organizational)
    4. Determine training methods
    5. Process TTT gaps
    6. Generate learning objectives (with PMT customization)
    7. Structure pyramid output
    8. Generate strategy comparison

    Request Body:
        {
            "organization_id": 28,
            "selected_strategies": [
                {"strategy_id": 1, "strategy_name": "Continuous support"},
                {"strategy_id": 6, "strategy_name": "Train the trainer"}
            ],
            "pmt_context": {  // Optional
                "processes": "ISO 26262, ASPICE",
                "methods": "Scrum, V-Model",
                "tools": "DOORS, JIRA"
            }
        }

    Response (Success):
        {
            "success": true,
            "data": {
                "main_pyramid": {
                    "levels": {1: {...}, 2: {...}, 4: {...}, 6: {...}},
                    "metadata": {...}
                },
                "train_the_trainer": {...} or null,
                "validation": {...},
                "strategy_comparison": {...}
            },
            "metadata": {
                "organization_id": 28,
                "selected_strategies": [...],
                "pmt_customization": true/false,
                "has_roles": true/false,
                "generation_timestamp": "2025-11-25T...",
                "processing_time_seconds": 0.45
            }
        }

    Response (Error):
        {
            "success": false,
            "error": "Error description",
            "error_type": "INVALID_REQUEST" | "ORGANIZATION_NOT_FOUND" | "INTERNAL_ERROR",
            "details": {...}
        }
    """
    try:
        from app.services.learning_objectives_core import generate_complete_learning_objectives

        data = request.get_json()

        # Validate request
        if not data:
            return jsonify({
                'success': False,
                'error': 'Request body is required',
                'error_type': 'INVALID_REQUEST'
            }), 400

        if 'organization_id' not in data:
            return jsonify({
                'success': False,
                'error': 'Missing organization_id in request body',
                'error_type': 'INVALID_REQUEST'
            }), 400

        if 'selected_strategies' not in data or not isinstance(data['selected_strategies'], list):
            return jsonify({
                'success': False,
                'error': 'Missing or invalid selected_strategies in request body (must be array)',
                'error_type': 'INVALID_REQUEST'
            }), 400

        organization_id = data['organization_id']
        pmt_context = data.get('pmt_context', None)  # Optional - can be from request or DB

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found',
                'error_type': 'ORGANIZATION_NOT_FOUND'
            }), 404

        # IMPORTANT: Always read strategies from DB for consistent hashing
        # The frontend sends strategies, but we re-read from DB to ensure consistent formatting
        selected_strategies_db = LearningStrategy.query.filter_by(
            organization_id=organization_id,
            selected=True
        ).order_by(LearningStrategy.priority.asc()).all()

        if not selected_strategies_db:
            return jsonify({
                'success': False,
                'error': 'No learning strategies selected for this organization',
                'error_type': 'NO_STRATEGIES'
            }), 400

        # Format strategies consistently with GET endpoint
        selected_strategies = [
            {
                'strategy_id': s.strategy_template_id or s.id,
                'strategy_name': s.strategy_name
            }
            for s in selected_strategies_db
        ]

        # If PMT context not provided in request, try to get from database
        if not pmt_context:
            pmt_record = OrganizationPMTContext.query.filter_by(organization_id=organization_id).first()
            if pmt_record and pmt_record.is_complete():
                pmt_context = {
                    'processes': pmt_record.processes,
                    'methods': pmt_record.methods,
                    'tools': pmt_record.tools
                }
                print(f"[api_generate_learning_objectives] PMT loaded from DB: {pmt_context is not None}")

        print(f"[api_generate_learning_objectives] Generating for org {organization_id}")
        print(f"[api_generate_learning_objectives] Strategies: {len(selected_strategies)}")
        print(f"[api_generate_learning_objectives] PMT customization: {pmt_context is not None}")

        # Generate learning objectives (Week 2 implementation)
        result = generate_complete_learning_objectives(
            org_id=organization_id,
            selected_strategies=selected_strategies,
            pmt_context=pmt_context
        )

        print(f"[api_generate_learning_objectives] Success - Processing time: {result['metadata']['processing_time_seconds']}s")

        return jsonify(result), 200

    except ValueError as e:
        print(f"[api_generate_learning_objectives] Validation error: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': 'VALIDATION_ERROR'
        }), 400

    except Exception as e:
        print(f"[api_generate_learning_objectives] Unexpected error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An unexpected error occurred during learning objectives generation',
            'error_type': 'INTERNAL_ERROR',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>', methods=['GET'])
def api_get_learning_objectives(organization_id):
    """
    Get generated learning objectives for an organization (CACHE ONLY)

    This endpoint only returns cached/previously generated objectives.
    It does NOT trigger LLM generation. Use POST /generate to create new objectives.

    Path Parameters:
        organization_id: Organization ID

    Response (Success - cached data exists):
        {
            "success": true,
            "pathway": "ROLE_BASED" | "TASK_BASED" | "ROLE_BASED_DUAL_TRACK" | "TASK_BASED_DUAL_TRACK",
            "data": {...},
            "metadata": {...}
        }

    Response (No cached data):
        {
            "success": false,
            "error": "No learning objectives generated yet",
            "error_type": "NOT_GENERATED"
        }
    """
    try:
        from app.services.learning_objectives_core import (
            compute_input_hash, get_cached_objectives
        )

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found',
                'error_type': 'ORGANIZATION_NOT_FOUND'
            }), 404

        # Get selected strategies from database
        selected_strategies_db = LearningStrategy.query.filter_by(
            organization_id=organization_id,
            selected=True
        ).order_by(LearningStrategy.priority.asc()).all()

        if not selected_strategies_db:
            return jsonify({
                'success': False,
                'error': 'No learning strategies selected for this organization',
                'error_type': 'NO_STRATEGIES',
                'details': {
                    'message': 'Please select at least one learning strategy in Phase 1 Task 3'
                }
            }), 400

        # Format strategies for hash computation
        selected_strategies = [
            {
                'strategy_id': s.strategy_template_id or s.id,
                'strategy_name': s.strategy_name
            }
            for s in selected_strategies_db
        ]

        # Get PMT context from database (optional)
        pmt_context = None
        pmt_record = OrganizationPMTContext.query.filter_by(organization_id=organization_id).first()
        if pmt_record and pmt_record.is_complete():
            pmt_context = {
                'processes': pmt_record.processes,
                'methods': pmt_record.methods,
                'tools': pmt_record.tools
            }

        # Compute input hash and check cache
        input_hash = compute_input_hash(organization_id, selected_strategies, pmt_context)
        print(f"[api_get_learning_objectives] Checking cache for org {organization_id}")
        print(f"[api_get_learning_objectives] Input hash: {input_hash[:16]}...")

        # Try to get cached result
        cached_result = get_cached_objectives(organization_id, input_hash)

        if cached_result:
            print(f"[api_get_learning_objectives] Cache HIT - returning cached data")
            return jsonify(cached_result), 200
        else:
            # Also check if ANY cache exists (even with different hash)
            # This handles the case where PMT was updated but objectives weren't regenerated
            from models import GeneratedLearningObjectives
            any_cache = GeneratedLearningObjectives.query.filter_by(
                organization_id=organization_id
            ).first()

            if any_cache:
                # Return stale cache with a warning
                print(f"[api_get_learning_objectives] Returning STALE cache (hash mismatch)")
                result = any_cache.objectives_data
                if isinstance(result, str):
                    import json
                    result = json.loads(result)
                result['metadata'] = result.get('metadata', {})
                result['metadata']['from_cache'] = True
                result['metadata']['stale'] = True
                result['metadata']['stale_reason'] = 'Input parameters changed. Click "Generate" to update.'
                return jsonify(result), 200

            # No cache at all - return NOT_GENERATED
            print(f"[api_get_learning_objectives] No cache exists - NOT_GENERATED")
            return jsonify({
                'success': False,
                'error': 'No learning objectives generated yet. Please click "Generate Learning Objectives" to create them.',
                'error_type': 'NOT_GENERATED'
            }), 404

    except ValueError as e:
        print(f"[api_get_learning_objectives] Validation error: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': 'VALIDATION_ERROR'
        }), 400

    except Exception as e:
        print(f"[api_get_learning_objectives] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An error occurred during learning objectives generation',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/pmt-context', methods=['GET', 'PATCH'])
def api_pmt_context(organization_id):
    """
    Get or update PMT (Processes, Methods, Tools) context for an organization

    PMT context enables deep customization of learning objectives for 2 specific strategies:
    - "Needs-based project-oriented training"
    - "Continuous support"

    GET Response:
        {
            "organization_id": 28,
            "processes": "Agile development, DevOps deployment",
            "methods": "Scrum, Kanban, TDD",
            "tools": "JIRA, Confluence, Git",
            "industry_specific_context": "Medical device development, ISO 13485",
            "is_complete": true
        }

    PATCH Request Body:
        {
            "processes": "Updated processes",
            "methods": "Updated methods",
            "tools": "Updated tools",
            "industry_specific_context": "Updated industry context"
        }
    """
    try:
        from models import PMTContext

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        if request.method == 'GET':
            # Fetch existing PMT context
            pmt = PMTContext.query.filter_by(organization_id=organization_id).first()

            if not pmt:
                return jsonify({
                    'success': True,
                    'data': {
                        'organization_id': organization_id,
                        'processes': None,
                        'methods': None,
                        'tools': None,
                        'industry': None,
                        'additionalContext': None,
                        'is_complete': False
                    }
                }), 200

            return jsonify({
                'success': True,
                'data': {
                    'organization_id': pmt.organization_id,
                    'processes': pmt.processes,
                    'methods': pmt.methods,
                    'tools': pmt.tools,
                    'industry': pmt.industry,
                    'additionalContext': pmt.additional_context,
                    'is_complete': pmt.is_complete(),
                    'created_at': pmt.created_at.isoformat() if pmt.created_at else None,
                    'updated_at': pmt.updated_at.isoformat() if pmt.updated_at else None
                }
            }), 200

        elif request.method == 'PATCH':
            # Update PMT context
            data = request.get_json()

            if not data:
                return jsonify({
                    'success': False,
                    'error': 'Missing request body'
                }), 400

            # Get or create PMT context
            pmt = PMTContext.query.filter_by(organization_id=organization_id).first()

            if not pmt:
                pmt = PMTContext(organization_id=organization_id)
                db.session.add(pmt)

            # Update fields
            if 'processes' in data:
                pmt.processes = data['processes']
            if 'methods' in data:
                pmt.methods = data['methods']
            if 'tools' in data:
                pmt.tools = data['tools']
            if 'industry' in data:
                pmt.industry = data['industry']
            if 'additionalContext' in data:
                pmt.additional_context = data['additionalContext']

            db.session.commit()

            print(f"[api_pmt_context] Updated PMT context for org {organization_id}")

            return jsonify({
                'success': True,
                'organization_id': pmt.organization_id,
                'processes': pmt.processes,
                'methods': pmt.methods,
                'tools': pmt.tools,
                'industry': pmt.industry,
                'additionalContext': pmt.additional_context,
                'is_complete': pmt.is_complete(),
                'updated_at': pmt.updated_at.isoformat() if pmt.updated_at else None
            }), 200

    except Exception as e:
        print(f"[api_pmt_context] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'An error occurred',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/validation', methods=['GET'])
def api_get_validation_results(organization_id):
    """
    Get validation results for an organization

    Uses Design v5 validation (Algorithm 2: Mastery Requirements Validation)
    which checks if selected strategies can meet role requirements.

    Response:
        {
            "success": true,
            "organization_id": 28,
            "pathway": "ROLE_BASED" | "TASK_BASED",
            "has_roles": true | false,
            "validation": {
                "status": "OK" | "INADEQUATE",
                "severity": "NONE" | "MEDIUM" | "HIGH",
                "message": "...",
                "affected": [...],
                "recommendations": [...]
            }
        }
    """
    try:
        from app.services.learning_objectives_core import (
            check_if_org_has_roles,
            calculate_combined_targets,
            validate_mastery_requirements
        )

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        # Check if organization has roles
        has_roles = check_if_org_has_roles(organization_id)
        pathway = 'ROLE_BASED' if has_roles else 'TASK_BASED'

        # Get selected strategies from database
        selected_strategies_db = LearningStrategy.query.filter_by(
            organization_id=organization_id,
            selected=True
        ).all()

        if not selected_strategies_db:
            return jsonify({
                'success': False,
                'error': 'No learning strategies selected',
                'error_type': 'NO_STRATEGIES'
            }), 400

        # Format strategies
        selected_strategies = [
            {
                'strategy_id': s.strategy_template_id or s.id,
                'strategy_name': s.strategy_name
            }
            for s in selected_strategies_db
        ]

        # Calculate targets
        targets_result = calculate_combined_targets(selected_strategies)
        main_targets = targets_result['main_targets']

        # Run validation (Algorithm 2)
        validation_result = validate_mastery_requirements(
            organization_id,
            selected_strategies,
            main_targets
        )

        return jsonify({
            'success': True,
            'organization_id': organization_id,
            'pathway': pathway,
            'has_roles': has_roles,
            'validation': validation_result
        }), 200

    except Exception as e:
        print(f"[api_get_validation_results] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An error occurred during validation',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/prerequisites', methods=['GET'])
def api_check_prerequisites(organization_id):
    """
    Check if prerequisites are met for generating learning objectives

    This is a lightweight endpoint for frontend validation before
    enabling the "Generate Objectives" button.

    Response:
        {
            "valid": true,
            "completion_rate": 100.0,
            "pathway": "ROLE_BASED",
            "selected_strategies_count": 2,
            "role_count": 3
        }

    or

        {
            "valid": false,
            "error": "Insufficient assessment data",
            "completion_rate": 45.0,
            "required_rate": 70.0
        }
    """
    try:
        from app.services.pathway_determination import validate_prerequisites

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'valid': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        result = validate_prerequisites(organization_id)

        if result.get('valid'):
            return jsonify(result), 200
        else:
            return jsonify(result), 400

    except Exception as e:
        print(f"[api_check_prerequisites] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'valid': False,
            'error': 'An error occurred',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/setup', methods=['POST'])
@jwt_required()
def api_setup_phase2_task3(organization_id):
    """
    Setup Phase 2 Task 3 strategies for an organization

    Automatically creates learning_strategy instances that reference global strategy_template records.
    This endpoint should be called once per organization, typically during organization creation
    or when first enabling Phase 2 Task 3.

    Requirements:
    - User must be authenticated
    - Organization must exist
    - Organization must not already have strategies setup

    Returns:
        200: Setup successful
        400: Setup failed (organization already has strategies)
        404: Organization not found
        500: Server error

    Example request:
        POST /api/phase2/learning-objectives/30/setup

    Example response:
        {
            "success": true,
            "organization_id": 30,
            "organization_name": "New Company",
            "strategies_created": 7,
            "strategies": [
                {"name": "Common basic understanding", "requires_pmt": false},
                ...
            ]
        }
    """
    try:
        print(f"[api_setup_phase2_task3] Setting up Phase 2 Task 3 for org {organization_id}")

        # Verify organization exists
        org = Organization.query.filter_by(id=organization_id).first()
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        # Call setup function (pass db.session for transaction management)
        result = setup_phase2_task3_strategies(organization_id, db_session=db.session)

        if result['success']:
            print(f"[api_setup_phase2_task3] Successfully setup {result['strategies_created']} strategies for org {organization_id}")
            return jsonify(result), 200
        else:
            print(f"[api_setup_phase2_task3] Setup failed for org {organization_id}: {result.get('error')}")
            # If already has strategies, return 400 (client error)
            if 'already has' in result.get('error', ''):
                return jsonify(result), 400
            else:
                return jsonify(result), 500

    except Exception as e:
        print(f"[api_setup_phase2_task3] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An error occurred during setup',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/users', methods=['GET'])
def api_get_assessment_users(organization_id):
    """
    Get detailed list of users and their assessment status

    This endpoint returns a list of all users in the organization with their
    assessment completion status, useful for the Assessment Monitor UI.

    Response:
        {
            "success": true,
            "organization_id": 28,
            "total_users": 9,
            "users_with_assessments": 9,
            "users": [
                {
                    "user_id": 39,
                    "username": "lowmaturity",
                    "email": null,
                    "has_assessment": true,
                    "last_completed": "2025-11-01T17:17:28",
                    "status": "completed"
                },
                ...
            ]
        }
    """
    try:
        from models import User, UserAssessment
        from sqlalchemy import func

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        # Query users with their latest assessment
        users_query = db.session.query(
            User.id,
            User.username,
            User.email,
            func.max(UserAssessment.completed_at).label('last_completed')
        ).outerjoin(
            UserAssessment,
            User.id == UserAssessment.user_id
        ).filter(
            User.organization_id == organization_id
        ).group_by(
            User.id,
            User.username,
            User.email
        ).order_by(
            User.id
        )

        users_data = users_query.all()

        # Format user data
        users_list = []
        users_with_assessments = 0

        for user_id, username, email, last_completed in users_data:
            has_assessment = last_completed is not None
            if has_assessment:
                users_with_assessments += 1

            users_list.append({
                'user_id': user_id,
                'username': username,
                'email': email if email else None,
                'has_assessment': has_assessment,
                'completed_at': last_completed.isoformat() if last_completed else None,
                'status': 'completed' if has_assessment else 'pending'
            })

        return jsonify({
            'success': True,
            'organization_id': organization_id,
            'total_users': len(users_list),
            'users_with_assessments': users_with_assessments,
            'completion_rate': round((users_with_assessments / len(users_list) * 100), 2) if users_list else 0,
            'users': users_list
        }), 200

    except Exception as e:
        print(f"[api_get_assessment_users] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An error occurred',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/add-strategy', methods=['POST'])
def api_add_recommended_strategy(organization_id):
    """
    Add a recommended strategy to organization's selected strategies

    This endpoint allows adding a strategy that was recommended by the validation layer.
    If the strategy requires PMT context, it must be provided in the request.

    Request Body:
        {
            "strategy_name": "Continuous support",
            "pmt_context": {
                "processes": "...",
                "methods": "...",
                "tools": "...",
                "industry_specific_context": "..."
            },
            "regenerate": true
        }

    Response (Success):
        {
            "success": true,
            "message": "Strategy added successfully",
            "strategy": {
                "id": 3,
                "name": "Continuous support",
                "selected": true
            },
            "pmt_required": true,
            "pmt_provided": true,
            "regenerated_objectives": {...}  // Only if regenerate=true
        }

    Response (Error - PMT Missing):
        {
            "success": false,
            "error": "PMT context required",
            "message": "This strategy requires company PMT context for deep customization",
            "pmt_required": true,
            "required_fields": ["processes", "methods", "tools", "industry_specific_context"]
        }
    """
    try:
        from models import PMTContext, LearningStrategy, StrategyTemplate, StrategyTemplateCompetency
        from app.services.learning_objectives_text_generator import check_if_strategy_needs_pmt
        from app.services.pathway_determination import generate_learning_objectives

        data = request.get_json()

        if not data or 'strategy_name' not in data:
            return jsonify({
                'success': False,
                'error': 'Missing strategy_name in request body'
            }), 400

        strategy_name = data['strategy_name']
        pmt_context_data = data.get('pmt_context')
        regenerate = data.get('regenerate', True)  # Default to regenerate

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        print(f"[api_add_recommended_strategy] Adding strategy '{strategy_name}' to org {organization_id}")

        # Find the strategy
        strategy = LearningStrategy.query.filter_by(
            organization_id=organization_id,
            strategy_name=strategy_name
        ).first()

        if not strategy:
            return jsonify({
                'success': False,
                'error': f'Strategy "{strategy_name}" not found for this organization',
                'message': 'Strategy must be created first before adding'
            }), 404

        # Check if strategy already selected
        if strategy.selected:
            return jsonify({
                'success': False,
                'error': 'Strategy already selected',
                'message': f'Strategy "{strategy_name}" is already in selected strategies'
            }), 400

        # Check if strategy requires PMT context
        needs_pmt = check_if_strategy_needs_pmt(strategy_name)

        if needs_pmt:
            # PMT is required for this strategy
            if not pmt_context_data:
                return jsonify({
                    'success': False,
                    'error': 'PMT context required',
                    'message': 'This strategy requires company PMT context for deep customization',
                    'pmt_required': True,
                    'required_fields': ['processes', 'methods', 'tools', 'industry_specific_context']
                }), 400

            # Validate PMT context has required fields
            required_fields = ['processes', 'methods', 'tools', 'industry_specific_context']
            missing_fields = [field for field in required_fields if not pmt_context_data.get(field)]

            if missing_fields:
                return jsonify({
                    'success': False,
                    'error': 'Incomplete PMT context',
                    'message': f'Missing required PMT fields: {", ".join(missing_fields)}',
                    'pmt_required': True,
                    'missing_fields': missing_fields
                }), 400

            # Save or update PMT context
            pmt = PMTContext.query.filter_by(organization_id=organization_id).first()

            if not pmt:
                pmt = PMTContext(organization_id=organization_id)
                db.session.add(pmt)

            pmt.processes = pmt_context_data['processes']
            pmt.methods = pmt_context_data['methods']
            pmt.tools = pmt_context_data['tools']
            pmt.industry_specific_context = pmt_context_data['industry_specific_context']

            db.session.commit()

            print(f"[api_add_recommended_strategy] PMT context updated for org {organization_id}")

        # Mark strategy as selected
        strategy.selected = True

        # Set priority (highest + 1)
        max_priority = db.session.query(
            db.func.max(LearningStrategy.priority)
        ).filter_by(
            organization_id=organization_id,
            selected=True
        ).scalar()

        strategy.priority = (max_priority or 0) + 1

        db.session.commit()

        print(f"[api_add_recommended_strategy] Strategy '{strategy_name}' marked as selected with priority {strategy.priority}")

        # Prepare response
        response = {
            'success': True,
            'message': f'Strategy "{strategy_name}" added successfully',
            'strategy': {
                'id': strategy.id,
                'name': strategy.strategy_name,
                'description': strategy.strategy_description,
                'selected': strategy.selected,
                'priority': strategy.priority
            },
            'pmt_required': needs_pmt,
            'pmt_provided': needs_pmt and bool(pmt_context_data)
        }

        # Regenerate objectives if requested
        if regenerate:
            print(f"[api_add_recommended_strategy] Regenerating objectives with new strategy")
            objectives_result = generate_learning_objectives(organization_id)

            if objectives_result.get('success'):
                response['regenerated_objectives'] = objectives_result
                print(f"[api_add_recommended_strategy] Objectives regenerated successfully")
            else:
                print(f"[api_add_recommended_strategy] Warning: Regeneration failed: {objectives_result.get('error')}")
                response['regeneration_warning'] = objectives_result.get('error')

        return jsonify(response), 200

    except Exception as e:
        print(f"[api_add_recommended_strategy] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': 'An error occurred',
            'details': str(e)
        }), 500


@main_bp.route('/phase2/learning-objectives/<int:organization_id>/export', methods=['GET'])
def api_export_learning_objectives(organization_id):
    """
    Export learning objectives in various formats

    Query Parameters:
        format: 'json' | 'excel' | 'pdf' (required)
        strategy: Filter by specific strategy name (optional)
        include_validation: Include validation results (default: true)

    Examples:
        /api/phase2/learning-objectives/28/export?format=json
        /api/phase2/learning-objectives/28/export?format=excel&strategy=Foundation Workshop
        /api/phase2/learning-objectives/28/export?format=pdf&include_validation=true

    Response: File download with appropriate Content-Type
    """
    try:
        from flask import send_file, make_response
        from models import GeneratedLearningObjectives
        import io
        import json as json_lib
        from datetime import datetime

        # Get query parameters
        export_format = request.args.get('format', '').lower()
        strategy_filter = request.args.get('strategy')
        include_validation = request.args.get('include_validation', 'true').lower() == 'true'

        # Validate format
        if export_format not in ['json', 'excel', 'pdf']:
            return jsonify({
                'success': False,
                'error': 'Invalid format',
                'message': 'Format must be one of: json, excel, pdf',
                'valid_formats': ['json', 'excel', 'pdf']
            }), 400

        # Validate organization exists
        org = Organization.query.get(organization_id)
        if not org:
            return jsonify({
                'success': False,
                'error': f'Organization {organization_id} not found'
            }), 404

        print(f"[api_export_learning_objectives] Exporting objectives for org {organization_id} in {export_format} format")

        # Get cached learning objectives (prefer cached data for consistency with UI)
        cached = GeneratedLearningObjectives.query.filter_by(organization_id=organization_id).first()

        if not cached:
            return jsonify({
                'success': False,
                'error': 'No learning objectives generated yet',
                'message': 'Please generate learning objectives first from the LO dashboard'
            }), 400

        # Parse cached data
        result = cached.objectives_data
        if isinstance(result, str):
            result = json_lib.loads(result)

        if not result.get('success', True):
            return jsonify({
                'success': False,
                'error': 'Cached objectives contain errors',
                'details': result.get('error')
            }), 400

        # Filter by strategy if specified
        objectives_data = result.copy()
        if strategy_filter:
            filtered_objectives = {}
            for strategy_id, strategy_data in result.get('learning_objectives_by_strategy', {}).items():
                if strategy_data.get('strategy_name') == strategy_filter:
                    filtered_objectives[strategy_id] = strategy_data

            if not filtered_objectives:
                return jsonify({
                    'success': False,
                    'error': 'Strategy not found',
                    'message': f'No objectives found for strategy "{strategy_filter}"'
                }), 404

            objectives_data['learning_objectives_by_strategy'] = filtered_objectives

        # Remove validation results if not requested
        if not include_validation:
            objectives_data.pop('strategy_validation', None)
            objectives_data.pop('strategic_decisions', None)
            objectives_data.pop('cross_strategy_coverage', None)

        # Export based on format
        if export_format == 'json':
            return export_json(objectives_data, org.organization_name)

        elif export_format == 'excel':
            return export_excel(objectives_data, org.organization_name)

        elif export_format == 'pdf':
            return export_pdf(objectives_data, org.organization_name)

    except Exception as e:
        print(f"[api_export_learning_objectives] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': 'An error occurred during export',
            'details': str(e)
        }), 500


def export_json(data, org_name):
    """Export learning objectives as JSON file"""
    from flask import make_response
    import json as json_lib
    from datetime import datetime

    # Create JSON string with pretty printing
    json_str = json_lib.dumps(data, indent=2, ensure_ascii=False)

    # Create response
    response = make_response(json_str)
    response.headers['Content-Type'] = 'application/json'
    response.headers['Content-Disposition'] = f'attachment; filename="learning_objectives_{org_name.replace(" ", "_")}_{datetime.now().strftime("%Y%m%d")}.json"'

    print(f"[export_json] JSON export created for {org_name}")
    return response


def export_excel(data, org_name):
    """
    Export learning objectives as Excel file matching the Organizational View.

    Single sheet with:
    - Competency rows x Level columns (Knowing, Understanding, Applying)
    - Color coding: Green = Achieved, Yellow = Gap (training required), Gray = Not Targeted
    - LO texts shown as bullet points for Achieved and Training Required
    - Not Targeted cells are gray and show only "Not Targeted" text
    - PMT breakdown shown separately (Process, Method, Tool)
    """
    from flask import send_file
    from datetime import datetime
    import io
    import re

    try:
        import openpyxl
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils import get_column_letter
    except ImportError:
        return jsonify({
            'success': False,
            'error': 'Excel export not available',
            'message': 'openpyxl library not installed. Install with: pip install openpyxl'
        }), 500

    def format_lo_as_bullets(text):
        """Convert LO text to bullet points by splitting on sentences."""
        if not text:
            return ''
        # Split on periods followed by space or end, but keep sentences meaningful
        sentences = re.split(r'\.(?=\s|$)', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        if len(sentences) <= 1:
            return text  # Single sentence, return as-is
        # Format as bullet points
        return '\n'.join([f"* {s}." if not s.endswith('.') else f"* {s}" for s in sentences])

    def extract_objective_text(lo_data):
        """Extract clean objective text and PMT breakdown from various LO data formats."""
        if not lo_data:
            return '', None

        if isinstance(lo_data, str):
            return lo_data, None

        if isinstance(lo_data, dict):
            pmt_breakdown = None

            # Check for PMT breakdown in the learning_objective object
            if lo_data.get('has_pmt_breakdown') and lo_data.get('pmt_breakdown'):
                pmt_breakdown = lo_data['pmt_breakdown']

            # Check for objective_text field
            if 'objective_text' in lo_data:
                return lo_data['objective_text'], pmt_breakdown

            # Check for direct PMT fields (process, method, tool)
            if 'process' in lo_data or 'method' in lo_data or 'tool' in lo_data:
                # This is the PMT breakdown itself
                return '', {
                    'process': lo_data.get('process', ''),
                    'method': lo_data.get('method', ''),
                    'tool': lo_data.get('tool', '')
                }

            # Fallback: try to get any text-like field
            for key in ['text', 'content', 'description']:
                if key in lo_data:
                    return str(lo_data[key]), pmt_breakdown

        return str(lo_data) if lo_data else '', None

    def format_pmt_breakdown(pmt):
        """Format PMT breakdown with clear labels."""
        if not pmt:
            return ''
        parts = []
        if pmt.get('process'):
            parts.append(f"[PROCESS]\n{pmt['process']}")
        if pmt.get('method'):
            parts.append(f"[METHOD]\n{pmt['method']}")
        if pmt.get('tool'):
            parts.append(f"[TOOL]\n{pmt['tool']}")
        return '\n\n'.join(parts)

    # Color definitions
    HEADER_FILL = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
    HEADER_FONT = Font(bold=True, color='FFFFFF')
    ACHIEVED_FILL = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')  # Light green
    GAP_FILL = PatternFill(start_color='FFEB9C', end_color='FFEB9C', fill_type='solid')  # Light yellow/orange
    NOT_TARGETED_FILL = PatternFill(start_color='D9D9D9', end_color='D9D9D9', fill_type='solid')  # Gray
    NOT_TARGETED_FONT = Font(color='808080', italic=True)  # Gray italic text
    THIN_BORDER = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )

    # Level name mapping (without L1, L2, L4 suffixes)
    LEVEL_NAMES = {
        1: 'Knowing SE',
        2: 'Understanding SE',
        4: 'Applying SE'
    }

    # Create workbook - single sheet only
    wb = openpyxl.Workbook()
    sheet = wb.active
    sheet.title = 'Learning Objectives'

    # ========== EXTRACT DATA FROM API STRUCTURE ==========
    selected_strategies = data.get('selected_strategies', [])
    if not selected_strategies:
        selected_strategies = data.get('metadata', {}).get('selected_strategies', [])

    all_competencies = {}
    total_gaps = 0
    competencies_with_gaps = set()

    # Check for NEW format (data.main_pyramid)
    main_pyramid = data.get('data', {}).get('main_pyramid', {})
    levels_data = main_pyramid.get('levels', {})

    if levels_data:
        print(f"[export_excel] Using NEW format (data.main_pyramid)")
        for level_str, level_info in levels_data.items():
            level_num = int(level_str)
            if level_num not in [1, 2, 4]:
                continue
            for comp in level_info.get('competencies', []):
                comp_id = comp.get('competency_id')
                comp_name = comp.get('competency_name', f'Competency {comp_id}')
                status = comp.get('status', 'achieved')
                grayed_out = comp.get('grayed_out', False)
                lo_data = comp.get('learning_objective', '')
                target_level = comp.get('target_level', 0)
                current_level = comp.get('current_level', 0)

                if comp_id not in all_competencies:
                    all_competencies[comp_id] = {
                        'name': comp_name,
                        'target_level': target_level,
                        'current_level': current_level,
                        'levels': {}
                    }

                # Get gap_data roles if available
                gap_data = comp.get('gap_data', {})
                roles_data = gap_data.get('roles', {}) if gap_data else {}

                # Extract roles needing this level
                roles_needing = []
                for role_id, role_info in roles_data.items():
                    if isinstance(role_info, dict):
                        level_details = role_info.get('level_details', {}).get(level_num, {})
                        if level_details or level_num in role_info.get('levels_needed', []):
                            roles_needing.append({
                                'role_name': role_info.get('role_name', f'Role {role_id}'),
                                'users_needing': level_details.get('users_needing', role_info.get('users_needing_training', 0)),
                                'total_users': level_details.get('total_users', role_info.get('total_users', 0))
                            })

                all_competencies[comp_id]['levels'][level_num] = {
                    'status': status,
                    'grayed_out': grayed_out,
                    'learning_objective': lo_data,
                    'target_level': target_level,
                    'current_level': current_level,
                    'roles_needing': roles_needing
                }

                if status == 'training_required' and not grayed_out:
                    total_gaps += 1
                    competencies_with_gaps.add(comp_id)
    else:
        print(f"[export_excel] No NEW format data found")

    is_new_format = bool(levels_data)
    print(f"[export_excel] Found {len(all_competencies)} competencies, {total_gaps} gaps")

    # ========== HEADER SECTION ==========
    row = 1
    sheet.merge_cells('A1:D1')
    sheet['A1'] = 'Learning Objectives - Organizational View'
    sheet['A1'].font = Font(size=16, bold=True)
    sheet['A1'].alignment = Alignment(horizontal='center')
    row = 3

    strategy_names = ', '.join([s.get('name', s.get('strategy_name', 'Unknown')) for s in selected_strategies])
    sheet[f'A{row}'] = 'Selected Strategies:'
    sheet[f'A{row}'].font = Font(bold=True)
    sheet[f'B{row}'] = strategy_names if strategy_names else 'None'
    sheet.merge_cells(f'B{row}:D{row}')
    row += 1

    sheet[f'A{row}'] = 'Levels to Advance:'
    sheet[f'A{row}'].font = Font(bold=True)
    sheet[f'B{row}'] = total_gaps
    row += 1

    sheet[f'A{row}'] = 'Competencies with Gap:'
    sheet[f'A{row}'].font = Font(bold=True)
    sheet[f'B{row}'] = len(competencies_with_gaps)
    row += 2

    # Legend
    sheet[f'A{row}'] = 'Legend:'
    sheet[f'A{row}'].font = Font(bold=True)
    row += 1

    sheet[f'A{row}'] = 'Green'
    sheet[f'A{row}'].fill = ACHIEVED_FILL
    sheet[f'B{row}'] = 'Level achieved (no training needed)'
    row += 1

    sheet[f'A{row}'] = 'Yellow'
    sheet[f'A{row}'].fill = GAP_FILL
    sheet[f'B{row}'] = 'Gap exists (training required)'
    row += 1

    sheet[f'A{row}'] = 'Gray'
    sheet[f'A{row}'].fill = NOT_TARGETED_FILL
    sheet[f'A{row}'].font = NOT_TARGETED_FONT
    sheet[f'B{row}'] = 'Not targeted by selected strategies'
    row += 2

    # ========== COMPETENCY TABLE ==========
    matrix_start_row = row
    sorted_comp_ids = sorted(all_competencies.keys())

    # Headers: Competency | Knowing SE | Understanding SE | Applying SE (without L1, L2, L4)
    headers = ['Competency', 'Knowing SE', 'Understanding SE', 'Applying SE']
    for col_idx, header in enumerate(headers, 1):
        cell = sheet.cell(row=row, column=col_idx, value=header)
        cell.font = HEADER_FONT
        cell.fill = HEADER_FILL
        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        cell.border = THIN_BORDER
    row += 1

    for comp_id in sorted_comp_ids:
        comp_data = all_competencies[comp_id]
        comp_name = comp_data['name']

        # Competency name
        name_cell = sheet.cell(row=row, column=1, value=comp_name)
        name_cell.font = Font(bold=True)
        name_cell.alignment = Alignment(vertical='top', wrap_text=True)
        name_cell.border = THIN_BORDER

        if is_new_format:
            # Level columns (1, 2, 4)
            for col_idx, level_num in enumerate([1, 2, 4], 2):
                level_data = comp_data.get('levels', {}).get(level_num, {})
                cell = sheet.cell(row=row, column=col_idx)
                cell.border = THIN_BORDER
                cell.alignment = Alignment(vertical='top', wrap_text=True)

                if not level_data:
                    cell.value = 'Not Targeted'
                    cell.fill = NOT_TARGETED_FILL
                    cell.font = NOT_TARGETED_FONT
                    continue

                status = level_data.get('status', 'achieved')
                grayed_out = level_data.get('grayed_out', False)
                lo_data = level_data.get('learning_objective', '')
                target_level = level_data.get('target_level', 0)
                current_level = level_data.get('current_level', 0)

                # CRITICAL FIX: Must match frontend SimpleCompetencyCard.vue logic
                # 1. If status is already 'not_targeted', keep it
                # 2. If target_level is 0, this level is NOT TARGETED
                # 3. If level_num > target_level (showing higher level than target), it's NOT TARGETED
                # 4. If current_level >= target_level (and target_level > 0), status should be achieved (no gap)
                if status == 'not_targeted':
                    pass  # Keep the status as is
                elif target_level == 0:
                    status = 'not_targeted'
                elif level_num > target_level:
                    # This level column is higher than the competency's target level
                    # So this level is NOT targeted for this competency
                    status = 'not_targeted'
                elif current_level >= target_level:
                    status = 'achieved'

                # Determine the actual status based on backend logic
                # status: 'training_required' | 'achieved' | 'not_targeted'

                if status == 'not_targeted':
                    # NOT TARGETED - gray cell, no LO text
                    cell.value = 'Not Targeted'
                    cell.fill = NOT_TARGETED_FILL
                    cell.font = NOT_TARGETED_FONT

                elif status == 'achieved' or (grayed_out and status != 'training_required'):
                    # ACHIEVED - green cell with LO text
                    cell.fill = ACHIEVED_FILL

                    # Extract and format LO text
                    lo_text, pmt_breakdown = extract_objective_text(lo_data)

                    content_parts = []

                    if pmt_breakdown:
                        # Show PMT breakdown with clear sections
                        content_parts.append(format_pmt_breakdown(pmt_breakdown))
                    elif lo_text:
                        # Format as bullet points
                        content_parts.append(format_lo_as_bullets(lo_text))

                    cell.value = '\n'.join(content_parts) if content_parts else ''

                elif status == 'training_required' and not grayed_out:
                    # TRAINING REQUIRED - yellow cell with LO text and role info
                    cell.fill = GAP_FILL

                    content_parts = []

                    # Add role/user info for gaps
                    roles = level_data.get('roles_needing', [])
                    if roles:
                        role_strs = [f"{r.get('role_name', '?')} ({r.get('users_needing', 0)}/{r.get('total_users', 0)})" for r in roles]
                        content_parts.append(f"Roles: {', '.join(role_strs)}")
                        content_parts.append('')

                    # Extract and format LO text
                    lo_text, pmt_breakdown = extract_objective_text(lo_data)

                    if pmt_breakdown:
                        # Show PMT breakdown with clear sections
                        content_parts.append(format_pmt_breakdown(pmt_breakdown))
                    elif lo_text:
                        # Format as bullet points
                        content_parts.append(format_lo_as_bullets(lo_text))

                    cell.value = '\n'.join(content_parts) if content_parts else ''

                else:
                    # Fallback for any other case
                    cell.value = '-'
                    cell.fill = NOT_TARGETED_FILL

        row += 1

    # Column widths - increased for better readability
    sheet.column_dimensions['A'].width = 30
    sheet.column_dimensions['B'].width = 65
    sheet.column_dimensions['C'].width = 65
    sheet.column_dimensions['D'].width = 65

    # Set row heights for wrapped text - increased to accommodate full text
    for r in range(matrix_start_row + 1, row):
        sheet.row_dimensions[r].height = 200  # Increased from 120 to 200

    # Save to BytesIO
    excel_file = io.BytesIO()
    wb.save(excel_file)
    excel_file.seek(0)

    filename = f"learning_objectives_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    print(f"[export_excel] Excel export created for {org_name} with {len(all_competencies)} competencies, {total_gaps} gaps")

    return send_file(
        excel_file,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        as_attachment=True,
        download_name=filename
    )


def export_pdf(data, org_name):
    """Export learning objectives as PDF file"""
    from flask import make_response
    from datetime import datetime

    # For now, return a simple text-based PDF using reportlab
    try:
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.lib import colors
        import io
    except ImportError:
        return jsonify({
            'success': False,
            'error': 'PDF export not available',
            'message': 'reportlab library not installed. Install with: pip install reportlab'
        }), 500

    # Create PDF buffer
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []

    styles = getSampleStyleSheet()
    title_style = ParagraphStyle('CustomTitle', parent=styles['Heading1'], fontSize=24, textColor=colors.HexColor('#1976D2'))
    heading_style = ParagraphStyle('CustomHeading', parent=styles['Heading2'], fontSize=16, textColor=colors.HexColor('#424242'))

    # Title
    story.append(Paragraph(f'Learning Objectives Report', title_style))
    story.append(Spacer(1, 0.3*inch))

    # Organization info
    story.append(Paragraph(f'<b>Organization:</b> {org_name}', styles['Normal']))
    story.append(Paragraph(f'<b>Pathway:</b> {data.get("pathway", "N/A")}', styles['Normal']))
    story.append(Paragraph(f'<b>Completion Rate:</b> {data.get("completion_rate", 0):.1f}%', styles['Normal']))
    story.append(Paragraph(f'<b>Generated:</b> {datetime.now().strftime("%Y-%m-%d %H:%M")}', styles['Normal']))
    story.append(Spacer(1, 0.5*inch))

    # Selected strategies
    story.append(Paragraph('Selected Strategies', heading_style))
    for strategy in data.get('selected_strategies', []):
        story.append(Paragraph(f'• {strategy["name"]} (Priority {strategy["priority"]})', styles['Normal']))
    story.append(Spacer(1, 0.3*inch))

    # Learning objectives per strategy
    for strategy_id, strategy_data in data.get('learning_objectives_by_strategy', {}).items():
        story.append(PageBreak())

        strategy_name = strategy_data.get('strategy_name', f'Strategy {strategy_id}')
        story.append(Paragraph(strategy_name, heading_style))
        story.append(Spacer(1, 0.2*inch))

        # Summary
        summary = strategy_data.get('summary', {})
        story.append(Paragraph(f'<b>Summary:</b>', styles['Normal']))
        story.append(Paragraph(f'• Training Required: {summary.get("competencies_requiring_training", 0)} competencies', styles['Normal']))
        story.append(Paragraph(f'• Targets Achieved: {summary.get("competencies_targets_achieved", 0)} competencies', styles['Normal']))
        story.append(Spacer(1, 0.3*inch))

        # Trainable competencies table
        trainable = strategy_data.get('trainable_competencies', [])
        training_required = [c for c in trainable if c.get('status') == 'training_required']

        if training_required:
            story.append(Paragraph('<b>Learning Objectives:</b>', styles['Normal']))
            story.append(Spacer(1, 0.1*inch))

            for comp in training_required:
                story.append(Paragraph(f'<b>{comp.get("competency_name")}</b> (Gap: {comp.get("current_level", 0)} → {comp.get("target_level", 0)})', styles['Normal']))
                story.append(Paragraph(comp.get('learning_objective', 'N/A'), styles['BodyText']))
                story.append(Spacer(1, 0.2*inch))

    # Build PDF
    doc.build(story)
    buffer.seek(0)

    filename = f"learning_objectives_{org_name.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.pdf"

    print(f"[export_pdf] PDF export created for {org_name}")

    response = make_response(buffer.read())
    response.headers['Content-Type'] = 'application/pdf'
    response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'

    return response


# ==============================================================================
# PMT (Process, Method, Tool) Document Extraction Endpoints
# ==============================================================================

@main_bp.route('/phase2/extract-pmt-from-document', methods=['POST'])
def extract_pmt_from_document():
    """
    Extract Process, Method, and Tool information from uploaded documents.
    Uses OpenAI to analyze document text and extract structured PMT data.

    Accepts: PDF, DOCX, TXT files
    Returns: Structured PMT data with confidence scores
    """
    try:
        # Check if file is present
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'No file uploaded'}), 400

        file = request.files['file']
        organization_id = request.form.get('organization_id')

        if not file or file.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'}), 400

        if not organization_id:
            return jsonify({'success': False, 'error': 'organization_id is required'}), 400

        # Get file extension
        filename = file.filename.lower()
        current_app.logger.info(f"[PMT Extract] Processing file: {filename}")

        # Extract text based on file type
        extracted_text = None

        if filename.endswith('.txt'):
            extracted_text = file.read().decode('utf-8', errors='ignore')

        elif filename.endswith('.pdf'):
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(file)
                text_parts = []
                for page in pdf_reader.pages:
                    text_parts.append(page.extract_text())
                extracted_text = '\n'.join(text_parts)
            except Exception as e:
                current_app.logger.error(f"[ERROR] PDF extraction failed: {str(e)}")
                return jsonify({'success': False, 'error': f'Failed to extract text from PDF: {str(e)}'}), 500

        elif filename.endswith('.docx'):
            try:
                import docx
                doc = docx.Document(file)
                text_parts = [para.text for para in doc.paragraphs]
                # Also extract from tables
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            text_parts.append(cell.text)
                extracted_text = '\n'.join(text_parts)
            except Exception as e:
                current_app.logger.error(f"[ERROR] DOCX extraction failed: {str(e)}")
                return jsonify({'success': False, 'error': f'Failed to extract text from DOCX: {str(e)}'}), 500

        else:
            return jsonify({'success': False, 'error': 'Unsupported file format. Please upload PDF, DOCX, or TXT files.'}), 400

        if not extracted_text or len(extracted_text.strip()) < 50:
            return jsonify({'success': False, 'error': 'Document appears to be empty or too short'}), 400

        # Use OpenAI to extract PMT information
        from openai import OpenAI
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

        prompt = f"""You are an expert in analyzing Systems Engineering documentation.
Analyze the following document and extract Process, Method, and Tool information.

DEFINITIONS:
- PROCESS: Organizational workflows, procedures, roles/responsibilities, approval gates, review cycles.
  Examples: ISO standards followed, development lifecycle (V-model, Agile), quality procedures, RACI matrices.

- METHOD: Technical techniques and approaches used to perform engineering activities.
  Examples: Requirements analysis methods, modeling techniques (SysML, UML), trade-off analysis, design reviews.

- TOOL: Specific software, platforms, or tools used to support engineering work.
  Examples: DOORS (requirements), JIRA (project management), Catia Magic (modeling), Git (version control).

Analyze the document text and extract relevant information into these categories.
For each item extracted, provide:
1. The name/title of the item
2. A brief description
3. The category (process, method, or tool)
4. Confidence level (high, medium, low)

Document text:
{extracted_text[:12000]}

Return a JSON object with this structure:
{{
  "document_type": "process|method|tool|mixed",
  "document_summary": "Brief summary of what this document describes",
  "processes": [
    {{"name": "...", "description": "...", "confidence": "high|medium|low"}}
  ],
  "methods": [
    {{"name": "...", "description": "...", "confidence": "high|medium|low"}}
  ],
  "tools": [
    {{"name": "...", "description": "...", "confidence": "high|medium|low"}}
  ],
  "suggested_text": {{
    "processes": "Consolidated text description of all processes found",
    "methods": "Consolidated text description of all methods found",
    "tools": "Consolidated text description of all tools found"
  }}
}}

IMPORTANT: In the "suggested_text" fields:
- If you find items in a category, write a concise summary of what was found
- If NOTHING is found for a category, leave it as an EMPTY STRING ""
- Do NOT write messages like "No specific methods were identified" - just use ""

Return ONLY valid JSON, nothing else."""

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that extracts Process, Method, and Tool information from Systems Engineering documents. Always respond with valid JSON only."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )

            ai_response = response.choices[0].message.content.strip()

            # Remove markdown code blocks if present
            if ai_response.startswith('```'):
                ai_response = ai_response.split('```')[1]
                if ai_response.startswith('json'):
                    ai_response = ai_response[4:]
                ai_response = ai_response.strip()

            # Parse JSON response
            pmt_data = json.loads(ai_response)

            current_app.logger.info(f"[OK] Extracted PMT data from document - Type: {pmt_data.get('document_type')}")
            current_app.logger.info(f"[OK] Found: {len(pmt_data.get('processes', []))} processes, {len(pmt_data.get('methods', []))} methods, {len(pmt_data.get('tools', []))} tools")

            return jsonify({
                'success': True,
                'filename': file.filename,
                'pmt_data': pmt_data
            })

        except json.JSONDecodeError as e:
            current_app.logger.error(f"[ERROR] Failed to parse AI response: {str(e)}")
            current_app.logger.error(f"[ERROR] AI response was: {ai_response}")
            return jsonify({'success': False, 'error': 'Failed to parse PMT information from document'}), 500

    except Exception as e:
        current_app.logger.error(f"[ERROR] PMT document extraction failed: {str(e)}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase2/pmt-reference-examples', methods=['GET'])
def get_pmt_reference_examples():
    """
    Get list of available PMT reference example files.
    Returns metadata about example files that users can view/download.
    """
    try:
        import os
        examples_dir = os.path.join(current_app.root_path, '..', '..', '..', 'data', 'PMT', 'reference_examples')
        examples_dir = os.path.normpath(examples_dir)

        examples = []

        if os.path.exists(examples_dir):
            for filename in os.listdir(examples_dir):
                if filename.endswith('.txt') and filename.startswith('EXAMPLE_'):
                    filepath = os.path.join(examples_dir, filename)

                    # Determine type from filename
                    if 'PROCESS' in filename:
                        pmt_type = 'process'
                    elif 'METHOD' in filename:
                        pmt_type = 'method'
                    elif 'TOOL' in filename:
                        pmt_type = 'tool'
                    else:
                        pmt_type = 'unknown'

                    # Get file size
                    file_size = os.path.getsize(filepath)

                    # Create friendly name
                    friendly_name = filename.replace('EXAMPLE_', '').replace('_', ' ').replace('.txt', '')

                    examples.append({
                        'filename': filename,
                        'name': friendly_name,
                        'type': pmt_type,
                        'size': file_size,
                        'description': f'Example {pmt_type.upper()} document for reference'
                    })

        return jsonify({
            'success': True,
            'examples': examples
        })

    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to get PMT examples: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500


@main_bp.route('/phase2/pmt-reference-examples/<filename>', methods=['GET'])
def download_pmt_reference_example(filename):
    """
    Download a specific PMT reference example file.
    """
    try:
        import os
        from flask import send_file

        # Security: only allow specific example files
        if not filename.startswith('EXAMPLE_') or not filename.endswith('.txt'):
            return jsonify({'success': False, 'error': 'Invalid filename'}), 400

        # Prevent directory traversal
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({'success': False, 'error': 'Invalid filename'}), 400

        examples_dir = os.path.join(current_app.root_path, '..', '..', '..', 'data', 'PMT', 'reference_examples')
        examples_dir = os.path.normpath(examples_dir)
        filepath = os.path.join(examples_dir, filename)

        if not os.path.exists(filepath):
            return jsonify({'success': False, 'error': 'File not found'}), 404

        return send_file(
            filepath,
            mimetype='text/plain',
            as_attachment=True,
            download_name=filename
        )

    except Exception as e:
        current_app.logger.error(f"[ERROR] Failed to download PMT example: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
